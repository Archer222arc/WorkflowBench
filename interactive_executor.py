#!/usr/bin/env python3
"""
Interactive Execution Environment for MCP Workflow System
========================================================
Enables multi-turn interaction between LLM and tools
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from mcp_embedding_manager import MCPEmbeddingManager
import json
import random
import time
import re
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime
import logging
from enum import Enum

from tool_capability_manager import ToolCapabilityManager  # <- æ–°å¢è¿™ä¸€è¡Œ


logger = logging.getLogger(__name__)


class SuccessLevel(Enum):
    """ä»»åŠ¡æˆåŠŸçº§åˆ«"""
    FULL_SUCCESS = "full_success"
    PARTIAL_SUCCESS = "partial_success"
    FAILURE = "failure"
    
    @property
    def is_success(self):
        """æ˜¯å¦ç®—ä½œæŸç§ç¨‹åº¦çš„æˆåŠŸ"""
        return self in (SuccessLevel.FULL_SUCCESS, SuccessLevel.PARTIAL_SUCCESS)
    
    @property
    def score_multiplier(self):
        """è¯„åˆ†ä¹˜æ•°"""
        if self == SuccessLevel.FULL_SUCCESS:
            return 1.0
        elif self == SuccessLevel.PARTIAL_SUCCESS:
            return 0.6
        else:
            return 0.0

@dataclass
class ToolExecutionResult:
    """å•ä¸ªå·¥å…·æ‰§è¡Œçš„ç»“æœ"""
    tool_name: str
    success: bool
    output: Any
    error: Optional[str] = None
    execution_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ExecutionState:
    """æ‰§è¡ŒçŠ¶æ€ç®¡ç†"""
    task_id: str
    task_type: str
    required_tools: List[str]
    executed_tools: List[str] = field(default_factory=list)
    execution_history: List[ToolExecutionResult] = field(default_factory=list)
    current_step: int = 0
    task_completed: bool = False
    total_tokens_used: int = 0
    conversation_history: List[Dict[str, str]] = field(default_factory=list)
    
    def get_progress_summary(self) -> str:
        """è·å–å½“å‰æ‰§è¡Œè¿›åº¦æ‘˜è¦"""
        return f"Progress: {len(self.executed_tools)} tools executed, {self.current_step} steps completed"


class InteractiveExecutor:
    """äº¤äº’å¼æ‰§è¡Œå™¨ï¼Œæ”¯æŒå·¥å…·æœç´¢"""
    def __init__(self, tool_registry: Dict[str, Any], llm_client: Any = None,
                 max_turns: int = 10, success_rate: float = 0.8,
                 model: str = None, prompt_type: str = None, silent: bool = False,
                 idealab_key_index: Optional[int] = None):
        """åˆå§‹åŒ–æ‰§è¡Œå™¨
        
        Args:
            tool_registry: å·¥å…·æ³¨å†Œè¡¨
            llm_client: LLMå®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼Œä¸æä¾›æ—¶è‡ªåŠ¨è·å–ï¼‰
            max_turns: æœ€å¤§äº¤äº’è½®æ•°
            success_rate: å·¥å…·æ‰§è¡ŒæˆåŠŸç‡
            model: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œä¸æä¾›æ—¶è‡ªåŠ¨è·å–ï¼‰
            prompt_type: æç¤ºç±»å‹ï¼ˆç”¨äºIdealLab API keyé€‰æ‹©ï¼‰
            silent: é™é»˜æ¨¡å¼ï¼Œç¦ç”¨è°ƒè¯•è¾“å‡º
            idealab_key_index: IdealLab API keyç´¢å¼•ï¼ˆ0-2ï¼‰
        """
        self.tool_registry = tool_registry
        self.max_turns = max_turns
        self.success_rate = success_rate
        self.silent = silent
        
        # ä½¿ç”¨api_client_managerè·å–å®¢æˆ·ç«¯å’Œæ¨¡å‹
        if llm_client is None:
            if not self.silent:
                print("[InteractiveExecutor] No LLM client provided, initializing from api_client_manager")
            from api_client_manager import get_client_for_model, get_api_model_name
            self.model = model or "gpt-4o-mini"
            self.prompt_type = prompt_type  # ä¿å­˜prompt_type
            self.idealab_key_index = idealab_key_index  # ä¿å­˜idealab_key_indexç”¨äºéƒ¨ç½²åˆ‡æ¢
            self.llm_client = get_client_for_model(self.model, prompt_type, idealab_key_index)
            if not self.silent:
                print(f"[InteractiveExecutor] Initialized client with model: {self.model}")
                if prompt_type:
                    print(f"[InteractiveExecutor] Using prompt type: {prompt_type} for API key selection")
                print(f"[InteractiveExecutor] API model name: {get_api_model_name(self.model)}")
        else:
            # ä¿æŒå‘åå…¼å®¹
            self.llm_client = llm_client
            self.prompt_type = prompt_type  # ä¿å­˜prompt_type
            self.idealab_key_index = idealab_key_index  # ä¿å­˜idealab_key_indexç”¨äºéƒ¨ç½²åˆ‡æ¢
            if model is None:
                # å°è¯•ä»å®¢æˆ·ç«¯è·å–æ¨¡å‹åç§°
                from api_client_manager import APIClientManager
                manager = APIClientManager()
                manager._client = llm_client  # ä¸´æ—¶è®¾ç½®å®¢æˆ·ç«¯ä»¥è·å–æ¨¡å‹å
                self.model = manager.get_model_name("gpt-4o-mini")
            else:
                self.model = model
        
        # åˆå§‹åŒ–æ¨¡æ‹Ÿå™¨
        self.tool_simulators = self._initialize_simulators()
        
        # åˆå§‹åŒ–åµŒå…¥ç®¡ç†å™¨ç”¨äºå·¥å…·æœç´¢
        self.embedding_manager = None
        self._initialize_embedding_manager()
        
        # è·Ÿè¸ªæœç´¢å†å²
        self.search_history = []
        
        # åŠ è½½å®Œæ•´çš„å·¥å…·å®šä¹‰ï¼ˆåŒ…å«é”™è¯¯ä¿¡æ¯ï¼‰
        self.full_tool_registry = self._load_full_tool_registry() 
        self.tool_capability_manager = ToolCapabilityManager()
    
    def _load_full_tool_registry(self) -> Dict[str, Any]: 
        """åŠ è½½åŒ…å«å®Œæ•´MCP protocolå®šä¹‰çš„å·¥å…·æ³¨å†Œè¡¨"""
        import json
        from pathlib import Path
        
        # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
        possible_paths = [
            Path("mcp_generated_library/tool_registry_consolidated.json"),
            Path("mcp_generated_library/tool_registry.json"),
            Path("tool_registry_consolidated.json"),
            Path("tool_registry.json")
        ]
        
        for path in possible_paths:
            if path.exists():
                try:
                    with open(path, 'r') as f:
                        registry = json.load(f)
                        if not self.silent:
                            print(f"[INFO] Loaded full tool registry from {path}")
                        return registry
                except Exception as e:
                    if not self.silent:
                        print(f"[WARNING] Failed to load {path}: {e}")
        
        if not self.silent:
            print("[WARNING] Could not load full tool registry, using provided registry")
        return self.tool_registry

    def _initialize_simulators(self) -> Dict[str, callable]:
        """ä¸ºæ¯ç±»å·¥å…·åˆå§‹åŒ–æ¨¡æ‹Ÿå™¨"""
        return {
            'file_operations': self._simulate_file_operation,
            'data_processing': self._simulate_data_processing,
            'network': self._simulate_network_operation,
            'computation': self._simulate_computation,
            'integration': self._simulate_integration,
            'utility': self._simulate_utility
        }


    def _initialize_embedding_manager(self):
        """åˆå§‹åŒ–åµŒå…¥ç®¡ç†å™¨"""
        # ä½¿ç”¨å•ä¾‹æ¨¡å¼è·å–MCPEmbeddingManager
        from mcp_embedding_manager import get_embedding_manager
        self.embedding_manager = get_embedding_manager()
        
        # å°è¯•åŠ è½½ç°æœ‰ç´¢å¼•
        index_path = ".mcp_embedding_cache/tool_index.pkl"
        if os.path.exists(index_path):
            self.embedding_manager.load_index(index_path)
            if not self.silent:
                print("[INFO] Tool embedding index loaded successfully")
        else:
            if not self.silent:
                print("[WARNING] Tool embedding index not found. Tool search will be limited.")

    def _get_tool_attribute(self, tool_info: Any, attr: str, default: Any = None) -> Any:
        """
        å®‰å…¨åœ°è·å–å·¥å…·å±æ€§ï¼Œå…¼å®¹å­—å…¸å’Œ ToolCapability å¯¹è±¡

        Args:
            tool_info: å·¥å…·ä¿¡æ¯ï¼ˆå­—å…¸æˆ– ToolCapability å¯¹è±¡ï¼‰
            attr: å±æ€§å
            default: é»˜è®¤å€¼

        Returns:
            å±æ€§å€¼æˆ–é»˜è®¤å€¼
        """
        # å¦‚æœæ˜¯å¯¹è±¡ï¼Œä½¿ç”¨ getattr
        if hasattr(tool_info, attr):
            return getattr(tool_info, attr, default)
        # å¦‚æœæ˜¯å­—å…¸ï¼Œä½¿ç”¨ get
        elif isinstance(tool_info, dict):
            return tool_info.get(attr, default)
        else:
            return default
    
    def _evaluate_success_detailed(self, state: ExecutionState) -> Tuple[str, Dict[str, Any]]:
        """è¯„ä¼°ä»»åŠ¡æˆåŠŸçº§åˆ« - è¯¦ç»†ç‰ˆæœ¬"""
        
        evaluation_details = {
            'required_tools_coverage': 0.0,
            'sequence_correctness': 0.0,
            'has_output': False,
            'success_reasons': [],
            'failure_reasons': []
        }
        
        # 1. ä¸¥æ ¼æ£€æŸ¥required_toolsçš„å®Œæˆæƒ…å†µå’Œé¡ºåº
        if state.required_tools:
            # æ£€æŸ¥å“ªäº›required_toolsè¢«æˆåŠŸæ‰§è¡Œ
            successful_required = []
            required_execution_order = []
            
            for exec_result in state.execution_history:
                # å¤„ç†dictæˆ–å¯¹è±¡
                success = exec_result.get('success', False) if isinstance(exec_result, dict) else exec_result.success
                tool_name = exec_result.get('tool', exec_result.get('tool_name', '')) if isinstance(exec_result, dict) else exec_result.tool_name
                if success and tool_name in state.required_tools:
                    successful_required.append(tool_name)
                    if tool_name not in required_execution_order:
                        required_execution_order.append(tool_name)
            
            # è®¡ç®—è¦†ç›–ç‡
            coverage = len(set(successful_required)) / len(state.required_tools)
            evaluation_details['required_tools_coverage'] = coverage
            
            # æ£€æŸ¥é¡ºåºæ­£ç¡®æ€§
            if len(required_execution_order) == len(state.required_tools):
                # æ£€æŸ¥é¡ºåºæ˜¯å¦ä¸required_toolsåˆ—è¡¨ä¸€è‡´
                sequence_correct = required_execution_order == state.required_tools
                evaluation_details['sequence_correctness'] = 1.0 if sequence_correct else 0.0
                
                # å®Œå…¨æˆåŠŸï¼šæ‰€æœ‰å·¥å…·æˆåŠŸä¸”é¡ºåºæ­£ç¡®
                if coverage == 1.0 and sequence_correct:
                    state.task_completed = True
                    evaluation_details['success_reasons'].append("All required tools executed in correct order")
                    return "full_success", evaluation_details
            else:
                evaluation_details['sequence_correctness'] = 0.0
        else: 
            print(state)
            raise ValueError("Execution state has no required tools defined.")
        
        # 2. æ£€æŸ¥è¾“å‡ºç”Ÿæˆ
        output_keywords = [
            'writer', 'export', 'save', 'output', 'post', 
            'publish', 'store', 'emit', 'notify', 'report', 
            'generate', 'filter', 'aggregator', 'compressor'
        ]
        
        for exec_result in state.execution_history:
            # å¤„ç†dictæˆ–å¯¹è±¡
            success = exec_result.get('success', False) if isinstance(exec_result, dict) else exec_result.success
            tool_name = exec_result.get('tool', exec_result.get('tool_name', '')) if isinstance(exec_result, dict) else exec_result.tool_name
            if success:
                tool_lower = tool_name.lower()
                if any(keyword in tool_lower for keyword in output_keywords):
                    evaluation_details['has_output'] = True
                    break
        
        # 3. éƒ¨åˆ†æˆåŠŸåˆ¤å®šæ¡ä»¶
        partial_success_conditions = []
        
        # æ¡ä»¶Aï¼šå®Œæˆäº†å¤§éƒ¨åˆ†required_toolsï¼ˆ>=60%ï¼‰
        if state.required_tools and evaluation_details['required_tools_coverage'] >= 0.6:
            partial_success_conditions.append("Completed 60%+ of required tools")
        
        # æ¡ä»¶Bï¼šæœ‰è¾“å‡ºç”Ÿæˆ
        if evaluation_details['has_output']:
            partial_success_conditions.append("Generated output")
        
        # æ¡ä»¶Cï¼šè¾¾åˆ°äº†ç‰¹å®šä»»åŠ¡ç±»å‹çš„æœ€ä½è¦æ±‚
        successful_count = sum(1 for r in state.execution_history if r.success)
        task_min_requirements = {
            'simple_task': 1,
            'basic_task': 2,
            'data_pipeline': 2,
            'api_integration': 2,
            'multi_stage_pipeline': 3
        }
        
        min_required = task_min_requirements.get(state.task_type, 2)
        if successful_count >= min_required:
            partial_success_conditions.append(f"Met minimum tool requirement ({successful_count}/{min_required})")
        
        # æ¡ä»¶Dï¼šæœ‰æ˜ç¡®çš„å®Œæˆä¿¡å·
        has_completion_signal = False
        for conv in state.conversation_history:
            if conv['role'] == 'assistant' and self._check_completion_signal(conv['content']):
                has_completion_signal = True
                partial_success_conditions.append("Explicit completion signal")
                break
        
        # åˆ¤å®šéƒ¨åˆ†æˆåŠŸ
        if len(partial_success_conditions) >= 2:  # è‡³å°‘æ»¡è¶³2ä¸ªæ¡ä»¶
            state.task_completed = True
            evaluation_details['success_reasons'] = partial_success_conditions
            return "partial_success", evaluation_details
        
        # 4. å¤±è´¥åˆ¤å®š
        failure_reasons = []
        
        if state.required_tools:
            if evaluation_details['required_tools_coverage'] < 0.5:
                failure_reasons.append(f"Low required tools coverage: {evaluation_details['required_tools_coverage']:.0%}")
        
        if successful_count < min_required:
            failure_reasons.append(f"Insufficient tools executed: {successful_count} < {min_required}")
        
        if not evaluation_details['has_output'] and state.task_type in ['data_pipeline', 'multi_stage_pipeline']:
            failure_reasons.append("No output generated for pipeline task")
        
        evaluation_details['failure_reasons'] = failure_reasons
        return "failure", evaluation_details



    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºï¼ŒåŒ…å«å·¥å…·æœç´¢å’Œè¯¦æƒ…æŸ¥è¯¢è¯´æ˜"""
        base_prompt = """You are an AI assistant executing workflow tasks in an automated testing environment. 
    Your goal is to complete the given task by using appropriate tools.

    IMPORTANT TEST ENVIRONMENT RULES:
    - This is an automated test environment with no human interaction
    - When tools require parameters, use reasonable default values
    - NEVER ask the user for input, file paths, or clarification
    - For file paths, use generic defaults like "data/input.json" or "data/output.json"
    - For URLs, use example URLs like "https://api.example.com/data"
    - For any options or formats, use sensible defaults (e.g., JSON format)

    CRITICAL EXECUTION MODE:
    - Execute ONE tool at a time
    - Wait for feedback after each tool execution before proceeding
    - Do NOT list multiple tool calls in a single response
    - After receiving feedback, decide the next action based on the results

    Tool Discovery:
    - Search for tools: <tool_search>your search query</tool_search>
    - Get tool details: <tool_info>tool_name</tool_info>

    Examples:
    - <tool_search>file reader writer</tool_search>
    - <tool_info>data_processing_aggregator</tool_info>

    Tool Execution:
    After understanding the tools, execute them using: <tool_call>tool_name</tool_call>

    IMPORTANT: Only include ONE <tool_call> per response. Wait for the execution result before proceeding.

    Guidelines:
    1. Analyze the task to understand what tools you need
    2. Search for relevant tools using descriptive queries
    3. Use tool_info to understand parameters, dependencies, and error handling
    4. Execute tools ONE AT A TIME in the logical order required by the task
    5. WAIT for feedback after each tool execution
    6. Pay attention to tool dependencies - execute dependent tools first
    7. Handle errors based on the error codes in tool info
    8. Use default values for all parameters - do not ask for user input
    9. Complete the task and indicate when finished

    Available tool categories: file_operations, data_processing, network, computation, integration, utility"""
        
        return base_prompt
    
    def execute_interactive(self, initial_prompt: str, task_instance: Dict,
                        workflow: Optional[Dict] = None, prompt_type: str = "baseline") -> Dict:
        """æ‰§è¡Œäº¤äº’å¼å·¥ä½œæµï¼Œæ”¯æŒå·¥å…·æœç´¢å’Œè¯¦æƒ…æŸ¥è¯¢"""
        # é‡ç½®æœç´¢å†å²
        self.search_history = []
        
        # åˆ›å»ºæ‰§è¡ŒçŠ¶æ€
        state = ExecutionState(
            task_id=task_instance.get('id', 'unknown'),
            task_type=task_instance.get('task_type', 'general'),
            required_tools=task_instance.get('required_tools', [])
        )
        
        # ä¿®æ”¹åˆå§‹promptï¼Œæ·»åŠ å·¥å…·æœç´¢å’Œè¯¦æƒ…æŸ¥è¯¢è¯´æ˜
        enhanced_prompt = self._enhance_prompt_with_search_info(initial_prompt, prompt_type)
        
        # å¼€å§‹äº¤äº’å¾ªç¯
        conversation = [
            {"role": "system", "content": self._get_system_prompt()},
            {"role": "user", "content": enhanced_prompt}
        ]
        
        start_time = time.time()
        
        for turn in range(self.max_turns):
            if not self.silent:
                print(f"\n[TURN {turn+1}/{self.max_turns}]")
            
            # 1. è·å–LLMå“åº”
            response = self._get_llm_response(conversation, state)
            if response is None:
                # APIå¤±è´¥åæ— æ³•ç»§ç»­ï¼Œè®°å½•APIé—®é¢˜å¹¶ç»“æŸ
                if not self.silent:
                    print(f"  [API_FAILURE] API failed (timeout or max retries)")
                if not hasattr(state, 'api_issues'):
                    state.api_issues = []
                
                # æ£€æŸ¥stateä¸­æ˜¯å¦æœ‰è¶…æ—¶æ ‡è®°
                if hasattr(state, 'timeout_occurred') and state.timeout_occurred:
                    # æ‰€æœ‰æ¨¡å‹ç»Ÿä¸€çš„è¶…æ—¶æ—¶é—´
                    timeout_seconds = 150
                    issue_type = f'API timeout after {timeout_seconds} seconds'
                    state.error_type = 'timeout'  # è®¾ç½®é”™è¯¯ç±»å‹ä¸ºtimeout
                else:
                    issue_type = 'API failed after max retries'
                    
                state.api_issues.append({
                    'turn': turn + 1,
                    'issue': issue_type,
                    'timestamp': datetime.now().isoformat()
                })
                break  # ç»“æŸæ‰§è¡Œï¼Œä½†ä¸ä¼šè¢«åˆ†ç±»ä¸ºå·¥ä½œæµé”™è¯¯
            
            # 2. æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·æœç´¢è¯·æ±‚
            search_queries = self._extract_tool_searches(response)
            if search_queries:
                # å¤„ç†å·¥å…·æœç´¢
                search_results = self._handle_tool_searches(search_queries, state)
                search_feedback = self._format_search_results(search_results)
                
                # æ·»åŠ æœç´¢ç»“æœåˆ°å¯¹è¯
                conversation.append({"role": "assistant", "content": response})
                conversation.append({"role": "user", "content": search_feedback})
                
                state.conversation_history.append({
                    "role": "assistant",
                    "content": response,
                    "turn": turn + 1,
                    "action": "search"
                })
                state.conversation_history.append({
                    "role": "user",
                    "content": search_feedback,
                    "turn": turn + 1
                })
                
                continue
            
            # 3. æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è¯¦æƒ…è¯·æ±‚ï¼ˆæ–°å¢ï¼‰
            info_requests = self._extract_tool_info_requests(response)
            if info_requests:
                # å¤„ç†å·¥å…·è¯¦æƒ…æŸ¥è¯¢
                info_feedback = self._get_tool_details(info_requests, state)
                
                # æ·»åŠ è¯¦æƒ…ç»“æœåˆ°å¯¹è¯
                conversation.append({"role": "assistant", "content": response})
                conversation.append({"role": "user", "content": info_feedback})
                
                state.conversation_history.append({
                    "role": "assistant",
                    "content": response,
                    "turn": turn + 1,
                    "action": "tool_info"
                })
                state.conversation_history.append({
                    "role": "user",
                    "content": info_feedback,
                    "turn": turn + 1
                })
                
                continue
            
            state.conversation_history.append({
                "role": "assistant",
                "content": response,
                "turn": turn + 1
            })
            
            # 4. è§£æå·¥å…·è°ƒç”¨å’Œæ™ºèƒ½æ ¼å¼æ£€æŸ¥
            tool_calls = self._parse_tool_calls(response)
            
            # 4a. å¿«é€Ÿæ£€æµ‹ï¼šå¦‚æœæ²¡æœ‰ä»»ä½•å¯è¯†åˆ«çš„actionï¼Œç«‹å³åé¦ˆ
            tool_searches = self._extract_tool_searches(response)
            tool_infos = self._extract_tool_info_requests(response)
            
            # å¦‚æœå“åº”è¶…è¿‡ä¸€å®šé•¿åº¦ä½†æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•actionæ ¼å¼
            if (len(response) > 50 and 
                not tool_calls and 
                not tool_searches and 
                not tool_infos and
                not self._check_completion_signal(response)):
                
                # ç«‹å³æä¾›ç®€å•ç›´æ¥çš„åé¦ˆ
                quick_help = self._generate_no_action_feedback(response, state)
                conversation.append({"role": "assistant", "content": response})
                conversation.append({"role": "user", "content": quick_help})
                
                state.conversation_history.append({
                    "role": "assistant",
                    "content": response,
                    "turn": turn + 1,
                    "no_action": True
                })
                state.conversation_history.append({
                    "role": "user",
                    "content": quick_help,
                    "turn": turn + 1,
                    "type": "no_action_help"
                })
                
                # è®°å½•æ ¼å¼é”™è¯¯ç»Ÿè®¡
                if not hasattr(state, 'format_error_count'):
                    state.format_error_count = 0
                state.format_error_count += 1
                
                if not self.silent:
                    print(f"  [NO_ACTION] Quick feedback provided - no valid action format detected")
                
                continue
            
            # 4b. æ›´è¯¦ç»†çš„æ ¼å¼é—®é¢˜æ£€æµ‹ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            format_issue_detected = self._detect_tool_call_format_issues(response, tool_calls, turn, state)
            
            # å¦‚æœæ£€æµ‹åˆ°æ ¼å¼é—®é¢˜ï¼Œæä¾›å¸®åŠ©å¹¶ç»§ç»­å¯¹è¯
            if format_issue_detected:
                format_help = self._generate_format_help_message(state)
                conversation.append({"role": "assistant", "content": response})
                conversation.append({"role": "user", "content": format_help})
                
                state.conversation_history.append({
                    "role": "assistant",
                    "content": response,
                    "turn": turn + 1,
                    "format_issue": True
                })
                state.conversation_history.append({
                    "role": "user",
                    "content": format_help,
                    "turn": turn + 1,
                    "type": "format_help"
                })
                
                # è®°å½•æ ¼å¼é”™è¯¯ç»Ÿè®¡
                if not hasattr(state, 'format_error_count'):
                    state.format_error_count = 0
                state.format_error_count += 1
                
                continue
            
            # 5. æ£€æŸ¥æ˜¯å¦å®Œæˆ - åªæœ‰åœ¨æ‰§è¡Œäº†æ‰€æœ‰å¿…éœ€å·¥å…·åæ‰å…è®¸å®Œæˆ
            required_tools_completed = all(tool in [r.tool_name for r in state.execution_history if r.success] 
                                         for tool in state.required_tools) if state.required_tools else False
            
            if required_tools_completed and self._check_completion_signal(response):
                state.task_completed = True
                if not self.silent:
                    print(f"  [COMPLETION] Task marked as completed - all required tools executed")
                break
            elif not tool_calls and not search_queries and not info_requests and len(state.execution_history) == 0:
                # åªæœ‰åœ¨å®Œå…¨æ²¡æœ‰ä»»ä½•è¡ŒåŠ¨æ—¶æ‰æå‰ç»ˆæ­¢
                state.task_completed = False
                if not self.silent:
                    print(f"  [EARLY_EXIT] No actions taken, continuing...")
                # ä¸è¦breakï¼Œç»§ç»­æ‰§è¡Œ
            
            # 6. æ‰§è¡Œå·¥å…·å¹¶ç”Ÿæˆåé¦ˆ
            if tool_calls:
                feedback = self._execute_tools_with_feedback(tool_calls, state)
                conversation.append({"role": "assistant", "content": response})
                conversation.append({"role": "user", "content": feedback})
                
                state.conversation_history.append({
                    "role": "user", 
                    "content": feedback,
                    "turn": turn + 1
                })
            
            # 7. æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»ˆæ­¢
            if self._should_terminate(state):
                if not self.silent:
                    print(f"  [TERMINATION] Execution terminated (criteria met)")
                break
        
        # è¯„ä¼°æˆåŠŸï¼ˆä½¿ç”¨åŸæœ‰æ–¹æ³•ï¼‰
        success = self._evaluate_success(state)
        success_level, evaluation_details = self._evaluate_success_detailed(state)
        
        # è®°å½•å¸®åŠ©ä¿¡æ¯ç”¨äºç»Ÿè®¡ï¼ˆä½†ä¸æ”¹å˜success_levelï¼‰
        if hasattr(state, 'format_error_count') and state.format_error_count > 0 and not self.silent:
            print(f"[ASSISTED] Task received {state.format_error_count} format helps, final result: {success_level}")
        
        # ç”Ÿæˆæ›´æ™ºèƒ½çš„é”™è¯¯æ¶ˆæ¯
        error_message = self._generate_intelligent_error_message(state, success_level, turn + 1)
        
        # ç”Ÿæˆæœ€ç»ˆç»“æœ
        execution_time = time.time() - start_time
        
        return {
            'state': state,
            'success': success,  # ä¿æŒå‘åå…¼å®¹
            'success_level': success_level,  # æ–°çš„è¯¦ç»†çº§åˆ«
            'evaluation_details': evaluation_details,  # è¯„ä¼°ç»†èŠ‚
            'tool_calls': state.executed_tools,
            'execution_time': execution_time,
            'conversation_history': state.conversation_history,
            'execution_history': state.execution_history,
            'search_history': self.search_history,  # æ·»åŠ æœç´¢å†å²
            'final_outputs': self._extract_final_outputs(state),
            'output_generated': evaluation_details.get('has_output', False),
            'prompt_type': prompt_type,
            'task_id': state.task_id,
            'executed_tools': state.executed_tools,
            'turns': turn + 1,
            'task_completed': state.task_completed,
            'execution_status': success_level,  # ç”¨success_levelä»£æ›¿execution_status
            'evaluation': evaluation_details,  # ç”¨evaluation_detailsä»£æ›¿evaluation
            'error_message': error_message,  # æ·»åŠ æ™ºèƒ½é”™è¯¯æ¶ˆæ¯
            'error_type': getattr(state, 'error_type', None),  # é”™è¯¯ç±»å‹ï¼ˆå¦‚timeoutï¼‰
            'format_error_count': getattr(state, 'format_error_count', 0),  # æ ¼å¼é”™è¯¯è®¡æ•°
            'format_issues': getattr(state, 'format_issues', []),  # æ ¼å¼é—®é¢˜åˆ—è¡¨
            'api_issues': getattr(state, 'api_issues', [])  # APIé—®é¢˜åˆ—è¡¨
        }
    

    def _parse_tool_calls(self, response: str) -> List[str]:
        """è§£æå·¥å…·è°ƒç”¨"""
        tool_calls = []
        
        # åŒ¹é… <tool_call>...</tool_call> æ ¼å¼
        pattern = r'<tool_call>(.*?)</tool_call>'
        matches = re.findall(pattern, response, re.DOTALL)
        
        for match in matches:
            tool_name = match.strip()
            if tool_name in self.tool_registry:
                tool_calls.append(tool_name)
                if not self.silent:
                    print(f"  [PARSE] Found tool call: {tool_name}")
            else:
                # å°è¯•æ¨¡ç³ŠåŒ¹é…
                matched_tool = self._fuzzy_match_tool(tool_name)
                if matched_tool:
                    tool_calls.append(matched_tool)
                    if not self.silent:
                        print(f"  [PARSE] Fuzzy matched '{tool_name}' to '{matched_tool}'")
                else:
                    if not self.silent:
                        print(f"  [PARSE] Unknown tool: {tool_name}")
        
        return tool_calls

    def _fuzzy_match_tool(self, tool_name: str) -> Optional[str]:
        """æ¨¡ç³ŠåŒ¹é…å·¥å…·å"""
        tool_lower = tool_name.lower()
        
        # ç²¾ç¡®åŒ¹é…ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
        for registered_tool in self.tool_registry:
            if registered_tool.lower() == tool_lower:
                return registered_tool
        
        # éƒ¨åˆ†åŒ¹é…
        for registered_tool in self.tool_registry:
            if tool_lower in registered_tool.lower() or registered_tool.lower() in tool_lower:
                return registered_tool
        
        return None
    
    def _detect_tool_call_format_issues(self, response: str, parsed_tools: List[str], turn: int, state) -> bool:
        """æ™ºèƒ½æ£€æµ‹å·¥å…·è°ƒç”¨æ ¼å¼é—®é¢˜"""
        # å¦‚æœå·²ç»è§£æåˆ°å·¥å…·è°ƒç”¨ï¼Œè¯´æ˜æ ¼å¼æ­£ç¡®
        if parsed_tools:
            return False
        
        # æ‰€æœ‰æ¨¡å‹ç»Ÿä¸€ä»ç¬¬1è½®å¼€å§‹æ£€æµ‹ï¼Œå¿«é€Ÿæä¾›åé¦ˆ
        if turn < 1:
            return False
        
        # æ£€æµ‹å¸¸è§çš„é”™è¯¯æ ¼å¼æ¨¡å¼
        format_issues = []
        
        # 1. æ£€æµ‹æ˜¯å¦å°è¯•ä½¿ç”¨å·¥å…·ä½†æ ¼å¼ä¸å¯¹
        potential_tool_patterns = [
            r'use[\s\w]*tool[\s\w]*([a-zA-Z_]+)',  # "use tool xyz" or "using tool xyz"
            r'call[\s\w]*([a-zA-Z_]+)',  # "call xyz" or "calling xyz"
            r'execute[\s\w]*([a-zA-Z_]+)',  # "execute xyz"
            r'run[\s\w]*([a-zA-Z_]+)',  # "run xyz"
            r'invoke[\s\w]*([a-zA-Z_]+)',  # "invoke xyz"
            r'\b([a-zA-Z_]+)\(.*\)',  # "tool_name(params)" function call style
            r'<([a-zA-Z_]+)>',  # "<tool_name>" simple bracket style
            r'\[([a-zA-Z_]+)\]',  # "[tool_name]" square bracket style
        ]
        
        potential_tools = []
        for pattern in potential_tool_patterns:
            matches = re.findall(pattern, response, re.IGNORECASE)
            for match in matches:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥å·¥å…·
                tool_name = match.strip()
                if self._is_likely_tool_name(tool_name):
                    potential_tools.append(tool_name)
                    format_issues.append(f"Detected potential tool '{tool_name}' in incorrect format")
        
        # 2. ç‰¹æ®Šæ£€æµ‹ï¼šå¦‚æœç”¨äº†tool_searchä½†æ²¡æœ‰tool_call
        has_tool_search = '<tool_search>' in response
        has_tool_call = '<tool_call>' in response
        
        if has_tool_search and not has_tool_call:
            format_issues.append("Used <tool_search> but no <tool_call> found - need to EXECUTE tools after searching")
        
        # 3. æ£€æµ‹æ˜¯å¦åœ¨æè¿°å·¥å…·ä½¿ç”¨ä½†æ²¡æœ‰å®é™…è°ƒç”¨
        action_keywords = ['need to', 'will use', 'should use', 'let me', 'i will', 'going to']
        tool_keywords = list(self.tool_registry.keys())[:20]  # å–å‰20ä¸ªå¸¸ç”¨å·¥å…·å
        
        for action in action_keywords:
            for tool in tool_keywords:
                if action in response.lower() and tool.lower() in response.lower():
                    format_issues.append(f"Mentioned using '{tool}' but no proper tool call found")
                    potential_tools.append(tool)
                    break
        
        # 4. å¦‚æœæ‰§è¡Œå†å²ä¸ºç©ºä¸”è½®æ•°è¾ƒå¤šï¼Œå¯èƒ½æ˜¯æ ¼å¼é—®é¢˜
        if len(state.execution_history) == 0 and turn >= 5:
            format_issues.append("No tools executed after multiple turns")
        
        # è®°å½•æ ¼å¼é—®é¢˜åˆ°çŠ¶æ€
        if format_issues:
            if not hasattr(state, 'format_issues'):
                state.format_issues = []
            state.format_issues.extend(format_issues)
            
            print(f"  [FORMAT_ISSUE] Turn {turn+1}: {'; '.join(format_issues)}")
            if potential_tools:
                print(f"  [FORMAT_ISSUE] Potential tools detected: {potential_tools}")
            
            return True
        
        return False
    
    def _is_likely_tool_name(self, name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¯èƒ½æ˜¯å·¥å…·å"""
        # æ£€æŸ¥æ˜¯å¦åœ¨å·¥å…·æ³¨å†Œè¡¨ä¸­
        if name in self.tool_registry:
            return True
        
        # æ¨¡ç³ŠåŒ¹é…
        if self._fuzzy_match_tool(name):
            return True
        
        # æ£€æŸ¥æ˜¯å¦ç¬¦åˆå·¥å…·åå‘½åè§„èŒƒ
        if re.match(r'^[a-zA-Z][a-zA-Z0-9_]*$', name) and len(name) > 2:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¸¸è§å·¥å…·è¯æ±‡
            tool_suffixes = ['er', 'or', 'manager', 'handler', 'service', 'client', 'api', 'tool']
            tool_prefixes = ['get', 'set', 'create', 'delete', 'update', 'send', 'fetch', 'parse']
            
            name_lower = name.lower()
            for suffix in tool_suffixes:
                if name_lower.endswith(suffix):
                    return True
            for prefix in tool_prefixes:
                if name_lower.startswith(prefix):
                    return True
        
        return False
    
    def _generate_format_help_message(self, state) -> str:
        """ç”Ÿæˆæ ¼å¼å¸®åŠ©æ¶ˆæ¯"""
        required_tools = state.required_tools if state.required_tools else []
        
        # åˆ†æä¸Šä¸€æ¡å“åº”ï¼Œæä¾›æ›´ç²¾ç¡®çš„åé¦ˆ
        last_response = state.conversation_history[-1]['content'] if state.conversation_history else ""
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†tool_search
        used_tool_search = '<tool_search>' in last_response
        used_tool_call = '<tool_call>' in last_response
        
        help_msg = "\n=== TOOL CALL FORMAT HELP ===\n"
        
        if used_tool_search and not used_tool_call:
            # æœ€å¸¸è§çš„æƒ…å†µï¼šæœç´¢äº†ä½†æ²¡æœ‰æ‰§è¡Œ
            help_msg += "ğŸš« ACTION NOT FOUND: No tool execution detected in your response.\n\n"
            help_msg += "You successfully searched for tools using <tool_search>, but you didn't execute any.\n"
            help_msg += "After finding tools, you MUST execute them using:\n"
            help_msg += "<tool_call>tool_name</tool_call>\n\n"
            help_msg += "Please execute the first tool NOW. For example:\n"
            if required_tools:
                help_msg += f"<tool_call>{required_tools[0]}</tool_call>\n"
            else:
                help_msg += "<tool_call>network_fetcher</tool_call>\n"
        elif not used_tool_search and not used_tool_call:
            # æ—¢æ²¡æœ‰æœç´¢ä¹Ÿæ²¡æœ‰æ‰§è¡Œ
            help_msg += "ğŸš« NO ACTION DETECTED: Your response contains no valid tool operations.\n\n"
            help_msg += "You need to either:\n"
            help_msg += "1. Search for tools: <tool_search>your query</tool_search>\n"
            help_msg += "2. Execute a tool: <tool_call>tool_name</tool_call>\n\n"
            help_msg += "Please take an action NOW.\n"
        else:
            # é€šç”¨æ ¼å¼é”™è¯¯
            help_msg += "âš ï¸ FORMAT ERROR: Tool call not detected.\n\n"
            help_msg += "You used <tool_search> correctly, but to EXECUTE tools you must use:\n"
            help_msg += "<tool_call>tool_name</tool_call>\n\n"
            help_msg += "IMPORTANT: After searching for tools, you need to EXECUTE them.\n"
            help_msg += "Example workflow:\n"
            help_msg += "1. <tool_search>query</tool_search> - Find tools (you did this âœ“)\n"
            help_msg += "2. <tool_call>tool_name</tool_call> - Execute tool (you need to do this)\n\n"
        
        if required_tools:
            help_msg += f"For this task, you need to use these tools: {', '.join(required_tools)}\n\n"
            help_msg += "EXAMPLES:\n"
            for tool in required_tools[:3]:  # Show examples for first 3 tools
                help_msg += f"<tool_call>{tool}</tool_call>\n"
        else:
            help_msg += "EXAMPLES:\n"
            sample_tools = list(self.tool_registry.keys())[:3]
            for tool in sample_tools:
                help_msg += f"<tool_call>{tool}</tool_call>\n"
        
        help_msg += "\nIMPORTANT: Use the EXACT format with angle brackets and 'tool_call' tags.\n"
        help_msg += "Please try again with the correct format.\n"
        help_msg += "=============================\n"
        
        return help_msg
    
    def _generate_no_action_feedback(self, response: str, state) -> str:
        """ç”Ÿæˆæ— actionæ£€æµ‹æ—¶çš„å¿«é€Ÿåé¦ˆ"""
        # åˆ†æå“åº”å†…å®¹ï¼ŒçŒœæµ‹å¯èƒ½çš„æ„å›¾
        response_lower = response.lower()
        
        # æ£€æŸ¥æ˜¯å¦åœ¨æè¿°æ„å›¾ä½†æ²¡æœ‰æ‰§è¡Œ
        intent_keywords = [
            'will', 'need to', 'should', 'let me', 'going to',
            'next', 'now', 'first', 'then', 'start'
        ]
        
        has_intent = any(keyword in response_lower for keyword in intent_keywords)
        
        # æ£€æŸ¥æ˜¯å¦æåˆ°äº†å·¥å…·ç›¸å…³è¯æ±‡
        tool_related = any(word in response_lower for word in [
            'tool', 'execute', 'call', 'use', 'fetch', 'validate', 'post',
            'network', 'data', 'api', 'process'
        ])
        
        # ç”Ÿæˆé’ˆå¯¹æ€§çš„åé¦ˆ
        if has_intent and tool_related:
            # çœ‹èµ·æ¥æƒ³æ‰§è¡Œæ“ä½œä½†æ ¼å¼é”™è¯¯
            feedback = "âŒ NO ACTION DETECTED - Format may be incorrect.\n\n"
            feedback += "I see you're trying to use tools, but I cannot detect any valid action format.\n"
            feedback += "Please use ONE of these formats:\n\n"
            feedback += "To search for tools:\n"
            feedback += "<tool_search>your search query</tool_search>\n\n"
            feedback += "To execute a tool:\n"
            feedback += "<tool_call>tool_name</tool_call>\n\n"
            feedback += "Example: <tool_call>network_fetcher</tool_call>\n"
            feedback += "\nIMPORTANT: Use the EXACT format with angle brackets."
        elif len(response) > 200:
            # é•¿å“åº”ä½†æ²¡æœ‰actionï¼Œå¯èƒ½åœ¨è§£é‡Šè€Œéæ‰§è¡Œ
            feedback = "âŒ NO ACTION FOUND - Please take an action.\n\n"
            feedback += "Your response contains explanations but no actual tool operations.\n"
            feedback += "Stop explaining and START DOING. Use:\n"
            feedback += "<tool_call>tool_name</tool_call> to execute a tool\n\n"
            if state.required_tools:
                feedback += f"Execute the first required tool NOW:\n"
                feedback += f"<tool_call>{state.required_tools[0]}</tool_call>"
        else:
            # é€šç”¨åé¦ˆ
            feedback = "âŒ NO VALID ACTION FORMAT DETECTED\n\n"
            feedback += "Your response must include one of these action formats:\n"
            feedback += "â€¢ <tool_search>query</tool_search> - to search for tools\n"
            feedback += "â€¢ <tool_call>tool_name</tool_call> - to execute a tool\n"
            feedback += "â€¢ <tool_info>tool_name</tool_info> - to get tool details\n\n"
            feedback += "Please try again with the correct format."
        
        # é€šç”¨æç¤ºï¼Œé€‚ç”¨äºæ‰€æœ‰æ¨¡å‹
        feedback += "\n\n[IMPORTANT: You must use the EXACT XML-style format shown above with angle brackets]"
        
        return feedback
    
    def _generate_intelligent_error_message(self, state, success_level: str, total_turns: int) -> Optional[str]:
        """ç”Ÿæˆæ™ºèƒ½çš„é”™è¯¯æ¶ˆæ¯"""
        if success_level in ['full_success', 'partial_success']:
            return None
        
        # å¦‚æœåªæ˜¯é‡åˆ°äº†APIé—®é¢˜ï¼Œä¸ç”Ÿæˆå·¥ä½œæµé”™è¯¯æ¶ˆæ¯
        if hasattr(state, 'api_issues') and state.api_issues:
            # å¦‚æœæ‰€æœ‰çš„å¤±è´¥éƒ½æ˜¯ç”±äºAPIé—®é¢˜ï¼Œä¸ç”Ÿæˆå·¥ä½œæµé”™è¯¯æ¶ˆæ¯
            if len(state.execution_history) == 0:
                # æ²¡æœ‰æ‰§è¡Œä»»ä½•å·¥å…·ä¸”æ˜¯å› ä¸ºAPIé—®é¢˜
                return None  # ä¸è¿”å›é”™è¯¯æ¶ˆæ¯ï¼Œé¿å…è¢«åˆ†ç±»ä¸ºå·¥ä½œæµé”™è¯¯
            # å¦åˆ™å¿½ç•¥APIé—®é¢˜ï¼Œç»§ç»­åˆ†æå…¶ä»–é”™è¯¯
        
        # åˆ†æå¤±è´¥åŸå› 
        if len(state.execution_history) == 0:
            # æ²¡æœ‰æ‰§è¡Œä»»ä½•å·¥å…·
            if hasattr(state, 'format_error_count') and state.format_error_count > 0:
                return f"Tool call format errors detected ({state.format_error_count} times) - Model unable to use correct <tool_call>tool_name</tool_call> format"
            elif total_turns >= self.max_turns:
                return f"Max turns reached ({total_turns}) with no tool calls - Likely tool call format recognition issue"
            else:
                return f"No tool calls executed in {total_turns} turns - Model may not understand tool call format"
        
        elif len(state.execution_history) > 0:
            # æœ‰æ‰§è¡Œä½†å¤±è´¥
            successful_tools = [r.tool_name for r in state.execution_history if r.success]
            failed_executions = [(r.tool_name, r.error) for r in state.execution_history if not r.success and r.error]
            
            # ä¼˜å…ˆè¿”å›å…·ä½“çš„å·¥å…·é”™è¯¯ï¼ˆä¿ç•™åŸå§‹é”™è¯¯ä¿¡æ¯ï¼‰
            if failed_executions:
                # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯åºåˆ—é”™è¯¯å¯¼è‡´çš„å¤±è´¥
                if state.required_tools and len(state.execution_history) >= 1:
                    execution_order = [r.tool_name for r in state.execution_history]
                    
                    # æ£€æŸ¥æ¯ä¸ªå¤±è´¥çš„å·¥å…·æ˜¯å¦å› ä¸ºé¡ºåºé—®é¢˜è€Œå¤±è´¥
                    for failed_tool, error in failed_executions:
                        if failed_tool in state.required_tools and error:
                            error_lower = error.lower()
                            # æ’é™¤æ˜ç¡®çš„ä¾èµ–é”™è¯¯ï¼ˆDEPENDENCY_ERRORé€šå¸¸æ˜¯ç³»ç»Ÿä¾èµ–ï¼Œä¸æ˜¯å·¥å…·é¡ºåºï¼‰
                            if 'dependency_error' in error_lower or 'dependency error' in error_lower:
                                continue  # è®©åé¢çš„é€»è¾‘å¤„ç†ä¾èµ–é”™è¯¯
                            
                            # å¦‚æœé”™è¯¯æš—ç¤ºç¼ºå°‘è¾“å…¥ï¼ˆè¿™é€šå¸¸æ˜¯åºåˆ—é—®é¢˜ï¼‰
                            if 'no input' in error_lower or 'missing data' in error_lower or 'data not found' in error_lower:
                                # æ£€æŸ¥è¿™ä¸ªå·¥å…·æ˜¯å¦åœ¨å®ƒçš„ä¾èµ–ä¹‹å‰æ‰§è¡Œäº†
                                tool_index = state.required_tools.index(failed_tool)
                                if tool_index > 0:
                                    # è¿™ä¸ªå·¥å…·æœ‰å‰ç½®ä¾èµ–
                                    required_before = state.required_tools[:tool_index]
                                    # æ£€æŸ¥æ‰§è¡Œå†å²ä¸­è¿™ä¸ªå·¥å…·ä¹‹å‰æ˜¯å¦æ‰§è¡Œäº†æ‰€æœ‰ä¾èµ–
                                    exec_index = execution_order.index(failed_tool) if failed_tool in execution_order else -1
                                    if exec_index >= 0:
                                        executed_before = execution_order[:exec_index]
                                        missing_deps = [t for t in required_before if t not in executed_before]
                                        if missing_deps:
                                            return f"Sequence order error: {failed_tool} executed before {missing_deps[0]} - {error}"
                
                # æŸ¥æ‰¾æœ€é‡è¦çš„é”™è¯¯ç±»å‹
                for tool_name, error in failed_executions:
                    if error:
                        error_lower = error.lower()
                        # ä¼˜å…ˆçº§1ï¼šè¶…æ—¶é”™è¯¯
                        if 'timeout' in error_lower:
                            return f"{error} (tool: {tool_name})"
                        # ä¼˜å…ˆçº§2ï¼šä¾èµ–é”™è¯¯
                        elif 'dependency' in error_lower or 'depend' in error_lower:
                            return f"{error} (tool: {tool_name})"
                        # ä¼˜å…ˆçº§3ï¼šå‚æ•°/è¾“å…¥é”™è¯¯
                        elif 'invalid' in error_lower or 'parameter' in error_lower or 'permission' in error_lower:
                            return f"{error} (tool: {tool_name})"
                
                # å¦‚æœæ²¡æœ‰åŒ¹é…ç‰¹å®šæ¨¡å¼ï¼Œè¿”å›ç¬¬ä¸€ä¸ªé”™è¯¯
                tool_name, error = failed_executions[0]
                return f"{error} (tool: {tool_name})"
            
            # å¦‚æœæ²¡æœ‰å…·ä½“é”™è¯¯ä¿¡æ¯ï¼Œä½¿ç”¨æ¦‚æ‹¬æ€§æè¿°
            failed_tools = [r.tool_name for r in state.execution_history if not r.success]
            if not successful_tools and failed_tools:
                return f"All {len(failed_tools)} tool calls failed - Tool execution errors"
            elif state.required_tools:
                missing_tools = [t for t in state.required_tools if t not in successful_tools]
                if missing_tools:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·é€‰æ‹©é”™è¯¯
                    if len(state.execution_history) > 0:
                        executed_tools = [r.tool_name for r in state.execution_history]
                        wrong_tools = [t for t in executed_tools if t not in state.required_tools]
                        if wrong_tools:
                            return f"Tool selection error: wrong tools used ({', '.join(wrong_tools)}) instead of required tools ({', '.join(state.required_tools)})"
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯åºåˆ—é¡ºåºé”™è¯¯
                    if state.required_tools and len(successful_tools) > 0:
                        # æ£€æŸ¥æ‰§è¡Œé¡ºåº
                        execution_order = [r.tool_name for r in state.execution_history if r.tool_name in state.required_tools]
                        if execution_order != state.required_tools[:len(execution_order)]:
                            return f"Sequence order error: tools executed in wrong order"
                    
                    return f"Required tools not completed: {', '.join(missing_tools)} - Task partially incomplete"
        
        # é»˜è®¤é”™è¯¯æ¶ˆæ¯
        return f"Task failed after {total_turns} turns - Unknown error"

    def _should_terminate(self, state: ExecutionState) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»ˆæ­¢æ‰§è¡Œ"""
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å¿…éœ€å·¥å…·éƒ½å·²å°è¯•
        if state.required_tools:
            all_required_attempted = all(tool in state.executed_tools for tool in state.required_tools)
            if all_required_attempted:
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰é‡è¯•çš„æœºä¼š
                successful_tools = {r.tool_name for r in state.execution_history if r.success}
                failed_required = [t for t in state.required_tools if t not in successful_tools]
                if failed_required:
                    print(f"  [CONTINUE] Required tools failed: {failed_required}, may retry")
                    # ä¸è¦ç«‹å³ç»ˆæ­¢ï¼Œè®©ç³»ç»Ÿæœ‰æœºä¼šé‡è¯•
                    return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤ªå¤šè¿ç»­å¤±è´¥
        if len(state.execution_history) >= 5:
            recent_failures = sum(1 for r in state.execution_history[-5:] if not r.success)
            if recent_failures >= 5:
                print(f"  [TERMINATE] Too many consecutive failures: {recent_failures}")
                return True
        
        # æ£€æŸ¥æ˜¯å¦æ‰§è¡Œäº†å¤ªå¤šå·¥å…·
        if len(state.executed_tools) > 15:
            print(f"  [TERMINATE] Too many tools executed: {len(state.executed_tools)}")
            return True
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å¾ªç¯ï¼ˆé‡å¤æ‰§è¡Œç›¸åŒå·¥å…·ï¼‰
        if len(state.executed_tools) >= 5:
            recent_tools = state.executed_tools[-5:]
            if len(set(recent_tools)) == 1:
                print(f"  [TERMINATE] Stuck in loop: repeating {recent_tools[0]}")
                return True
        
        return False

    def _enhance_prompt_with_search_info(self, original_prompt: str, prompt_type: str) -> str:
        """å¢å¼ºpromptï¼Œæ·»åŠ å·¥å…·æœç´¢å’Œè¯¦æƒ…æŸ¥è¯¢ä¿¡æ¯"""
        if prompt_type == "baseline":
            # å¯¹baseline promptç‰¹åˆ«å¤„ç†ï¼Œç§»é™¤åŸæœ‰çš„Available Toolséƒ¨åˆ†
            # å¹¶æ·»åŠ æœç´¢è¯´æ˜
            lines = original_prompt.split('\n')
            enhanced_lines = []
            skip_tools = False
            
            for line in lines:
                if line.strip().startswith("Available Tools:"):
                    skip_tools = True
                    # æ›¿æ¢ä¸ºæœç´¢å’Œè¯¦æƒ…æŸ¥è¯¢è¯´æ˜
                    enhanced_lines.append("Tool Search Available:")
                    enhanced_lines.append("You have access to a comprehensive tool library.")
                    enhanced_lines.append("Search for tools using: <tool_search>query</tool_search>")
                    enhanced_lines.append("Get tool details using: <tool_info>tool_name</tool_info>")
                    enhanced_lines.append("")
                    enhanced_lines.append("Examples:")
                    enhanced_lines.append("- <tool_search>data validation parser</tool_search>")
                    enhanced_lines.append("- <tool_info>data_processing_validator</tool_info>")
                    enhanced_lines.append("")
                elif skip_tools and (line.strip() == "" or not line.startswith("-")):
                    skip_tools = False
                    enhanced_lines.append(line)
                elif not skip_tools:
                    enhanced_lines.append(line)
            
            return '\n'.join(enhanced_lines)
        else:
            # å¯¹å…¶ä»–promptç±»å‹ï¼Œåœ¨åˆé€‚ä½ç½®æ·»åŠ æœç´¢å’Œè¯¦æƒ…æŸ¥è¯¢è¯´æ˜
            search_info = """

    Note: You can search for tools using <tool_search>query</tool_search> and get tool details using <tool_info>tool_name</tool_info>."""
            return original_prompt + search_info

    def _extract_tool_searches(self, response: str) -> List[str]:
        """æå–å·¥å…·æœç´¢æŸ¥è¯¢"""
        pattern = r'<tool_search>(.*?)</tool_search>'
        matches = re.findall(pattern, response, re.DOTALL)
        queries = [match.strip() for match in matches]
        
        for query in queries:
            print(f"  [SEARCH] Query: {query}")
        
        return queries
    

    def _handle_tool_searches(self, queries: List[str], state: ExecutionState) -> List[Dict]:
        """å¤„ç†å·¥å…·æœç´¢è¯·æ±‚ï¼Œè¿”å›å®Œæ•´çš„MCPåè®®ä¿¡æ¯"""
        all_results = []
        
        for query in queries:
            # è·Ÿè¸ªæœç´¢å†å²
            self.search_history.append({
                'query': query,
                'turn': state.current_step,
                'timestamp': datetime.now().isoformat()
            })
            

            search_results = self.embedding_manager.search(
                query=query,
                k=5  # è¿”å›å‰5ä¸ªæœ€ç›¸å…³çš„å·¥å…·
            )
            
            # æ ¼å¼åŒ–ç»“æœï¼ŒåŒ…å«å®Œæ•´çš„MCPåè®®ä¿¡æ¯
            formatted_results = []
            for result in search_results:
                # ç¡®ä¿å·¥å…·åœ¨æ³¨å†Œè¡¨ä¸­
                if result.tool_name in self.tool_registry:
                    # è·å–å®Œæ•´çš„MCPåè®®
                    mcp_protocol = result.mcp_protocol  # <- ä¿®æ”¹äº†è¿™éƒ¨åˆ†
                    
                    tool_info = {
                        'name': result.tool_name,
                        'description': mcp_protocol.get('description', ''),
                        'category': result.category,
                        'score': float(result.score),
                        # æ·»åŠ å®Œæ•´çš„MCPåè®®ä¿¡æ¯  # <- æ–°å¢äº†è¿™éƒ¨åˆ†
                        'parameters': mcp_protocol.get('parameters', []),
                        'returns': mcp_protocol.get('returns', []),
                        'errors': mcp_protocol.get('errors', []),
                        'dependencies': mcp_protocol.get('dependencies', []),
                        'metadata': mcp_protocol.get('metadata', {})
                    }
                    formatted_results.append(tool_info)
            
            all_results.append({
                'query': query,
                'results': formatted_results
            })

        
        return all_results
    

    def _simple_tool_search(self, query: str) -> List[Dict]:
        """ç®€å•çš„å…³é”®è¯åŒ¹é…å·¥å…·æœç´¢ï¼ˆé™çº§æ–¹æ¡ˆï¼‰ï¼Œè¿”å›å®Œæ•´MCPä¿¡æ¯"""
        print("å•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Š")
        query_words = query.lower().split()
        results = []
        
        # ä¼˜å…ˆä»å®Œæ•´æ³¨å†Œè¡¨è·å–ä¿¡æ¯  # <- æ–°å¢äº†è¿™éƒ¨åˆ†
        registry_to_use = self.full_tool_registry if hasattr(self, 'full_tool_registry') else self.tool_registry
        
        for tool_name, tool_spec in registry_to_use.items():
            # è®¡ç®—åŒ¹é…åˆ†æ•°
            score = 0
            tool_lower = tool_name.lower()
            desc_lower = str(tool_spec.get('description', '')).lower()
            
            for word in query_words:
                if word in tool_lower:
                    score += 2
                if word in desc_lower:
                    score += 1
            
            if score > 0:
                results.append({
                    'name': tool_name,
                    'description': tool_spec.get('description', ''),
                    'category': tool_spec.get('metadata', {}).get('category', 'unknown'),
                    'score': score / len(query_words),
                    # æ·»åŠ å®Œæ•´çš„MCPåè®®ä¿¡æ¯  # <- æ–°å¢äº†è¿™éƒ¨åˆ†
                    'parameters': tool_spec.get('parameters', []),
                    'returns': tool_spec.get('returns', []),
                    'errors': tool_spec.get('errors', []),
                    'dependencies': tool_spec.get('dependencies', []),
                    'metadata': tool_spec.get('metadata', {})
                })
        
        # æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å›å‰5ä¸ª
        results.sort(key=lambda x: x['score'], reverse=True)
        return results[:5]


    def _format_search_results(self, search_results: List[Dict]) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœï¼ŒåŒ…å«å®Œæ•´çš„MCPåè®®ä¿¡æ¯"""
        feedback_parts = ["Tool Search Results:"]
        
        for search in search_results:
            feedback_parts.append(f"\nQuery: '{search['query']}'")
            
            if 'error' in search:
                feedback_parts.append(f"Error: {search['error']}")
                continue
            
            if search['results']:
                feedback_parts.append("Found tools:")
                for i, tool in enumerate(search['results'][:5], 1):
                    feedback_parts.append(f"\n{i}. {tool['name']}")
                    feedback_parts.append(f"   Category: {tool['category']}")
                    feedback_parts.append(f"   Description: {tool['description']}")
                    if 'score' in tool:
                        feedback_parts.append(f"   Relevance: {tool['score']:.2f}")
                    
                    # æ·»åŠ å‚æ•°ä¿¡æ¯  # <- æ–°å¢äº†è¿™éƒ¨åˆ†
                    if 'parameters' in tool and tool['parameters']:
                        feedback_parts.append("   Parameters:")
                        for param in tool['parameters']:
                            param_str = f"      - {param.get('name', 'unnamed')} ({param.get('type', 'any')})"
                            if param.get('description'):
                                param_str += f": {param['description']}"
                            if param.get('required', True):
                                param_str += " [REQUIRED]"
                            else:
                                param_str += " [OPTIONAL]"
                                if 'default' in param:
                                    param_str += f" default={param['default']}"
                            feedback_parts.append(param_str)
                    else:
                        feedback_parts.append("   Parameters: None required")
                    
                    # æ·»åŠ è¿”å›å€¼ä¿¡æ¯
                    if 'returns' in tool and tool['returns']:
                        feedback_parts.append("   Returns:")
                        for ret in tool['returns']:
                            ret_str = f"      - {ret.get('name', 'unnamed')} ({ret.get('type', 'any')})"
                            if ret.get('description'):
                                ret_str += f": {ret['description']}"
                            feedback_parts.append(ret_str)
                    
                    # æ·»åŠ é”™è¯¯ä¿¡æ¯
                    if 'errors' in tool and tool['errors']:
                        feedback_parts.append("   Possible Errors:")
                        for err in tool['errors']:
                            err_str = f"      - {err.get('code', 'ERROR')}"
                            if err.get('description'):
                                err_str += f": {err['description']}"
                            feedback_parts.append(err_str)
                    
                    # æ·»åŠ ä¾èµ–ä¿¡æ¯
                    if 'dependencies' in tool and tool['dependencies']:
                        feedback_parts.append(f"   Dependencies: {', '.join(tool['dependencies'])}")
            else:
                feedback_parts.append("No matching tools found.")
        
        feedback_parts.append("\nYou can now use these tools with <tool_call>tool_name</tool_call>")
        
        return '\n'.join(feedback_parts)


    def _get_tool_details(self, tool_names: List[str], state: ExecutionState) -> str:
        """è·å–å·¥å…·çš„è¯¦ç»†MCPä¿¡æ¯"""
        # ç¡®ä¿å·²åŠ è½½å®Œæ•´çš„å·¥å…·æ³¨å†Œè¡¨
        if not hasattr(self, 'full_tool_registry'):
            self.full_tool_registry = self._load_full_tool_registry()
        
        feedback_parts = ["Tool Information:"]
        
        for tool_name in tool_names:
            # è·Ÿè¸ªä¿¡æ¯è¯·æ±‚å†å²
            self.search_history.append({
                'action': 'tool_info',
                'tool': tool_name,
                'turn': state.current_step,
                'timestamp': datetime.now().isoformat()
            })
            
            feedback_parts.append(f"\n=== {tool_name} ===")
            
            # ä»å®Œæ•´æ³¨å†Œè¡¨è·å–ä¿¡æ¯
            if tool_name in self.full_tool_registry:
                tool_spec = self.full_tool_registry[tool_name]
                
                # åŸºæœ¬ä¿¡æ¯
                feedback_parts.append(f"Description: {tool_spec.get('description', 'No description')}")
                feedback_parts.append(f"Category: {tool_spec.get('metadata', {}).get('category', 'general')}")
                
                # å‚æ•°è¯¦æƒ…
                parameters = tool_spec.get('parameters', [])
                if parameters:
                    feedback_parts.append("\nParameters:")
                    for param in parameters:
                        param_str = f"  - {param['name']} ({param['type']})"
                        if param.get('description'):
                            param_str += f": {param['description']}"
                        if param.get('required', True):
                            param_str += " [REQUIRED]"
                        else:
                            param_str += " [OPTIONAL]"
                            if 'default' in param:
                                param_str += f" default={param['default']}"
                        feedback_parts.append(param_str)
                else:
                    feedback_parts.append("Parameters: None required")
                
                # è¿”å›å€¼è¯¦æƒ…
                returns = tool_spec.get('returns', [])
                if returns:
                    feedback_parts.append("\nReturns:")
                    for ret in returns:
                        ret_str = f"  - {ret.get('name', 'unnamed')} ({ret.get('type', 'any')})"
                        if ret.get('description'):
                            ret_str += f": {ret['description']}"
                        feedback_parts.append(ret_str)
                
                # é”™è¯¯è¯¦æƒ…
                errors = tool_spec.get('errors', [])
                if errors:
                    feedback_parts.append("\nPossible Errors:")
                    for err in errors:
                        err_str = f"  - {err.get('code', 'ERROR')}"
                        if err.get('description'):
                            err_str += f": {err['description']}"
                        feedback_parts.append(err_str)
                
                # ä¾èµ–å…³ç³»
                dependencies = tool_spec.get('dependencies', [])
                if dependencies:
                    feedback_parts.append(f"\nDependencies: {', '.join(dependencies)}")
                    feedback_parts.append("  Note: These tools should be executed before this one")
                
                # ä½¿ç”¨ç¤ºä¾‹ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
                if tool_spec.get('metadata', {}).get('usage_hint'):
                    feedback_parts.append(f"\nUsage Hint: {tool_spec['metadata']['usage_hint']}")
                
            elif tool_name in self.tool_registry:
                # é™çº§ï¼šåªæœ‰åŸºæœ¬ä¿¡æ¯
                tool_info = self.tool_registry[tool_name]
                feedback_parts.append("Limited information available (full registry not loaded)")
                feedback_parts.append(f"Description: {self._get_tool_attribute(tool_info, 'description', 'No description')}")
                feedback_parts.append(f"Category: {self._get_tool_attribute(tool_info, 'category', 'general')}")
            else:
                feedback_parts.append(f"Tool '{tool_name}' not found in registry")
        
        feedback_parts.append("\nUse <tool_call>tool_name</tool_call> to execute a tool")
        
        return '\n'.join(feedback_parts)
    

    def _get_llm_response(self, conversation: List[Dict], state: ExecutionState) -> Optional[str]:
        """è·å–LLMçš„ä¸‹ä¸€æ­¥å“åº”"""
        # è°ƒç”¨LLM
        from api_client_manager import get_api_model_name
        import time
        import random
        
        # è·å–æ­£ç¡®çš„APIæ¨¡å‹åç§°
        api_model_name = get_api_model_name(self.model)
        print(f"[LLM_CALL] Using model: {self.model}, API name: {api_model_name}")
        
        # æ·»åŠ é‡è¯•é€»è¾‘å¤„ç†APIé™æµå’Œ400é”™è¯¯ï¼ˆä¸è®¡å…¥turnï¼‰
        max_retries = 5  # å¢åŠ é‡è¯•æ¬¡æ•°
        response = None
        for attempt in range(max_retries):
            try:
                # QPSæ§åˆ¶ - åœ¨æ¯æ¬¡å®é™…APIè°ƒç”¨å‰
                from qps_limiter import get_qps_limiter
                qps_limiter = get_qps_limiter(
                    self.model,
                    None,  # ä½¿ç”¨é»˜è®¤QPSè®¾ç½®
                    self.idealab_key_index if hasattr(self, 'idealab_key_index') else None
                )
                qps_limiter.acquire()  # ç­‰å¾…ç›´åˆ°å…è®¸å‘é€ä¸‹ä¸€ä¸ªè¯·æ±‚
                
                # åªä¼ é€’å¿…è¦å‚æ•°ï¼Œä¸è®¾ç½®max_tokenså’Œtemperature
                create_params = {
                    "model": api_model_name,
                    "messages": conversation
                }
                
                # è®¾ç½®APIè°ƒç”¨è¶…æ—¶æ—¶é—´ä¸º120ç§’
                # æ‰€æœ‰æ¨¡å‹ç»Ÿä¸€ä½¿ç”¨150ç§’è¶…æ—¶ï¼Œç»™äºˆå……è¶³çš„å“åº”æ—¶é—´
                timeout_seconds = 150
                
                response = self.llm_client.chat.completions.create(**create_params, timeout=timeout_seconds)
                break  # æˆåŠŸåˆ™è·³å‡ºå¾ªç¯
            except Exception as e:
                error_msg = str(e)
                print(f"[LLM_ERROR] Attempt {attempt + 1}/{max_retries}: {error_msg}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯è¶…æ—¶é”™è¯¯ï¼ˆè¶…æ—¶ä¸é‡è¯•ï¼Œç›´æ¥å¤±è´¥ï¼‰
                is_timeout = "timeout" in error_msg.lower() or "timed out" in error_msg.lower()
                if is_timeout:
                    print(f"[TIMEOUT] API call timed out after 150 seconds, not retrying")
                    state.timeout_occurred = True  # æ ‡è®°è¶…æ—¶å‘ç”Ÿ
                    return None  # ç›´æ¥è¿”å›å¤±è´¥ï¼Œä¸é‡è¯•
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯429é”™è¯¯ï¼ˆéœ€è¦åˆ‡æ¢éƒ¨ç½²ï¼‰
                is_429_error = "429" in error_msg or "Too Many Requests" in error_msg or "too many requests" in error_msg.lower()
                
                if is_429_error:
                    print(f"[429_ERROR] 429 Too Many Requests detected, attempting deployment switch...")
                    
                    # å°è¯•åˆ‡æ¢éƒ¨ç½²
                    if hasattr(self.llm_client, 'current_deployment'):
                        current_deployment = self.llm_client.current_deployment
                        print(f"[429_ERROR] Current deployment: {current_deployment}")
                        
                        # æ ‡è®°å½“å‰éƒ¨ç½²å¤±è´¥
                        try:
                            from smart_deployment_manager import get_deployment_manager
                            deployment_manager = get_deployment_manager()
                            deployment_manager.mark_deployment_failed(current_deployment, "429")
                            print(f"[429_ERROR] Marked {current_deployment} as failed due to 429 error")
                            
                            # è·å–æ–°çš„æœ€ä½³éƒ¨ç½²
                            new_deployment = deployment_manager.get_best_deployment(self.model)
                            if new_deployment and new_deployment != current_deployment:
                                print(f"[429_ERROR] Switching from {current_deployment} to {new_deployment}")
                                
                                # é‡æ–°åˆ›å»ºå®¢æˆ·ç«¯
                                from api_client_manager import get_client_for_model
                                idealab_key_index = getattr(self, 'idealab_key_index', None)
                                self.llm_client = get_client_for_model(self.model, self.prompt_type, idealab_key_index)
                                print(f"[429_ERROR] Successfully switched to new deployment: {getattr(self.llm_client, 'current_deployment', 'N/A')}")
                                
                                # é‡è¯•å½“å‰è¯·æ±‚ï¼ˆä¸è®¡å…¥é‡è¯•æ¬¡æ•°ï¼‰
                                continue
                            else:
                                print(f"[429_ERROR] No alternative deployment available for {self.model}")
                        except Exception as switch_error:
                            print(f"[429_ERROR] Failed to switch deployment: {switch_error}")
                    else:
                        print(f"[429_ERROR] Client does not support deployment switching")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„é”™è¯¯ï¼ˆä¸åŒ…æ‹¬è¶…æ—¶å’Œ429ï¼‰
                is_rate_limit = ("é™æµ" in error_msg or "rate limit" in error_msg.lower() or "PL-002" in error_msg) and not is_429_error
                is_400_error = "400" in error_msg or "Bad Request" in error_msg
                is_connection_error = ("Connection" in error_msg and "timeout" not in error_msg.lower())
                
                if is_rate_limit or is_400_error or is_connection_error or is_429_error:
                    if attempt < max_retries - 1:
                        # å‡å°‘é‡è¯•é—´éš”ï¼š0.5-1.5ç§’åŸºç¡€æ—¶é—´ï¼ŒæŒ‡æ•°é€€é¿æ›´æ¸©å’Œ
                        base_wait = random.uniform(0.5, 1.5)
                        wait_time = base_wait * (1.5 ** attempt)  # ä½¿ç”¨1.5è€Œä¸æ˜¯2ä½œä¸ºæŒ‡æ•°åŸºæ•°
                        wait_time = min(wait_time, 10)  # æœ€å¤§ç­‰å¾…10ç§’
                        
                        if not self.silent:
                            if is_400_error:
                                print(f"[RETRY] 400 error detected, waiting {wait_time:.1f}s before retry (not counting as turn)...")
                            elif is_rate_limit:
                                print(f"[RETRY] Rate limited, waiting {wait_time:.1f}s before retry...")
                            else:
                                print(f"[RETRY] Connection issue, waiting {wait_time:.1f}s before retry...")
                        
                        time.sleep(wait_time)
                        continue
                    else:
                        if not self.silent:
                            print(f"[ERROR] Max retries reached after {max_retries} attempts")
                            # è¿”å›Noneè¡¨ç¤ºAPIå¤±è´¥ï¼Œè®©ä¸»å¾ªç¯å¤„ç†
                            print(f"[API_FAILURE] All retries exhausted")
                        return None  # ä¸»å¾ªç¯ä¼šç»“æŸï¼Œä½†ä¸ä¼šè¢«ç»Ÿè®¡ä¸ºå·¥ä½œæµé”™è¯¯
                else:
                    # å…¶ä»–é”™è¯¯ä»ç„¶æŠ›å‡º
                    raise
        
        if response is None:
            return None  # è¿”å›Noneè®©è°ƒç”¨è€…å¤„ç†
        
        # æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆ
        if not hasattr(response, 'choices') or not response.choices:
            print(f"[ERROR] Invalid response structure: no choices")
            return None
        
        if not hasattr(response.choices[0], 'message') or not response.choices[0].message:
            print(f"[ERROR] Invalid response: no message")
            return None
        
        message = response.choices[0].message.content
        
        # æŸäº›æ¨¡å‹(DeepSeek-R1, gpt-oss-120bç­‰)ä½¿ç”¨reasoning_contentå­—æ®µ
        if not message and hasattr(response.choices[0].message, 'reasoning_content'):
            reasoning = response.choices[0].message.reasoning_content
            if reasoning:
                print(f"[INFO] Model {api_model_name}: Using reasoning_content instead of content")
                message = reasoning
        
        if not message:
            # æ‰“å°æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
            print(f"[ERROR] Empty message content from API")
            print(f"[DEBUG] Response finish_reason: {response.choices[0].finish_reason}")
            if hasattr(response, 'usage'):
                print(f"[DEBUG] Token usage - prompt: {response.usage.prompt_tokens}, completion: {response.usage.completion_tokens}")
            print(f"[DEBUG] Model: {api_model_name}")
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å­—æ®µåŒ…å«å†…å®¹
            if hasattr(response.choices[0].message, '__dict__'):
                print(f"[DEBUG] Message fields: {response.choices[0].message.__dict__.keys()}")
            return None
        
        # è®°å½•tokenä½¿ç”¨
        if hasattr(response, 'usage'):
            state.total_tokens_used += response.usage.total_tokens
        
        return message
            
    


    def _execute_tools_with_feedback(self, tool_calls: List[str], state: ExecutionState) -> str:
        """æ‰§è¡Œå·¥å…·å¹¶ç”Ÿæˆåé¦ˆæ¶ˆæ¯"""
        feedback_parts = []
        
        for tool_name in tool_calls:
            print(f"  [EXECUTING] {tool_name}")
            
            # æ‰§è¡Œå·¥å…·
            result = self._execute_single_tool(tool_name, state)
            
            # è®°å½•æ‰§è¡Œå†å²ï¼ˆåŒ…å«æˆåŠŸå’Œå¤±è´¥ï¼‰
            state.execution_history.append(result)
            state.current_step += 1
            
            # åªæœ‰æˆåŠŸçš„å·¥å…·æ‰è®°å½•åˆ° executed_tools
            success = result.get('success', False) if isinstance(result, dict) else result.success
            if success:
                state.executed_tools.append(tool_name)
            
            # ç”Ÿæˆåé¦ˆ
            if success:
                feedback = f"âœ… {tool_name} executed successfully.\nOutput: {json.dumps(result.output, indent=2)}"
                print(f"    Result: SUCCESS")
            else:
                feedback = f"âŒ {tool_name} failed.\nError: {result.error}"
                print(f"    Result: FAILED - {result.error}")
            
            feedback_parts.append(feedback)
        
        # ç»„åˆæ‰€æœ‰åé¦ˆ
        combined_feedback = "\n\n".join(feedback_parts)
        combined_feedback += f"\n\nCurrent progress: {len(state.executed_tools)} tools executed."
        
        # ç§»é™¤required_toolsæç¤ºï¼Œæ”¹ä¸ºé€šç”¨çš„è¿›åº¦ä¿¡æ¯  # <- ä¿®æ”¹äº†è¿™éƒ¨åˆ†
        if hasattr(state, 'task_type'):  # <- æ–°å¢
            # æä¾›ä»»åŠ¡ç±»å‹ç›¸å…³çš„é€šç”¨æç¤º  # <- æ–°å¢
            if state.task_type == 'simple_task':  # <- æ–°å¢
                combined_feedback += " Continue with your task processing."  # <- æ–°å¢
            elif state.task_type == 'data_pipeline':  # <- æ–°å¢
                combined_feedback += " Continue with the pipeline execution."  # <- æ–°å¢
            else:  # <- æ–°å¢
                combined_feedback += " Continue with the next step."  # <- æ–°å¢
        else:  # <- æ–°å¢
            combined_feedback += " What's your next action?"  # <- ä¿ç•™åŸæœ‰çš„é€šç”¨æç¤º
        
        combined_feedback += "\n- If successful, execute the next tool in your workflow"
        combined_feedback += "\n- If failed, consider alternatives or error handling"
        combined_feedback += "\n- If task is complete, indicate completion"
        combined_feedback += "\n\nRemember: Execute only ONE tool per response."
    
        
        return combined_feedback
    
    def _execute_single_tool(self, tool_name: str, state: ExecutionState) -> ToolExecutionResult:
        """æ‰§è¡Œå•ä¸ªå·¥å…·"""
        start_time = time.time()
        
        # è·å–å·¥å…·ç±»åˆ«
        category = self._get_tool_category(tool_name)
        simulator = self.tool_simulators.get(category, self._simulate_generic)
        
        # è®¡ç®—æˆåŠŸç‡
        success_rate = self._calculate_success_rate(tool_name, state)
        
        # æ¨¡æ‹Ÿæ‰§è¡Œ
        success = random.random() < success_rate
        
        if success:
            output = simulator(tool_name, state)
            error = None
        else:
            output = None
            error = self._generate_error_message(tool_name)
        
        execution_time = time.time() - start_time
        
        return ToolExecutionResult(
            tool_name=tool_name,
            success=success,
            output=output,
            error=error,
            execution_time=execution_time,
            metadata={'category': category, 'attempt': state.current_step}
        )
    

    def _calculate_success_rate(self, tool_name: str, state: ExecutionState) -> float:
        """è®¡ç®—å·¥å…·æˆåŠŸç‡ï¼ˆè€ƒè™‘ä¾èµ–å’ŒçŠ¶æ€ï¼‰"""
        rate = self.success_rate
        
        # æ£€æŸ¥ä¾èµ–
        tool_info = self.tool_registry.get(tool_name, {})
        dependencies = self._get_tool_attribute(tool_info, 'dependencies', [])  # <- ä¿®æ”¹ï¼šä½¿ç”¨ç»Ÿä¸€è®¿é—®æ–¹æ³•
        
        for dep in dependencies:
            if dep not in state.executed_tools:
                rate *= 0.5  # ä¾èµ–æœªæ»¡è¶³ï¼ŒæˆåŠŸç‡é™ä½
                print(f"    [DEPENDENCY] Missing: {dep}, success rate reduced")
            else:
                # æ£€æŸ¥ä¾èµ–æ˜¯å¦æˆåŠŸ
                dep_results = [r for r in state.execution_history if r.tool_name == dep]
                if dep_results and not dep_results[-1].success:
                    rate *= 0.7  # ä¾èµ–å¤±è´¥ï¼ŒæˆåŠŸç‡é™ä½
                    print(f"    [DEPENDENCY] Failed: {dep}, success rate reduced")
        
        # è¿ç»­å¤±è´¥æƒ©ç½š
        if len(state.execution_history) >= 3:
            recent_failures = sum(1 for r in state.execution_history[-3:] if not r.success)
            if recent_failures > 0:
                rate *= (0.9 ** recent_failures)
                print(f"    [PENALTY] Recent failures: {recent_failures}, success rate reduced")
        
        return max(0.1, min(0.95, rate))  # ä¿æŒåœ¨åˆç†èŒƒå›´
    
    # === å·¥å…·æ¨¡æ‹Ÿå™¨ ===
    
    def _simulate_file_operation(self, tool_name: str, state: ExecutionState) -> Dict:
        """æ¨¡æ‹Ÿæ–‡ä»¶æ“ä½œ"""
        operations = {
            'reader': {
                'content': f'File content with {random.randint(100, 1000)} lines',
                'size': random.randint(1024, 10240),
                'encoding': 'utf-8'
            },
            'writer': {
                'path': f'/output/result_{random.randint(1000, 9999)}.txt',
                'bytes_written': random.randint(1024, 5120),
                'status': 'success'
            },
            'scanner': {
                'files_found': random.randint(1, 20),
                'total_size': random.randint(10240, 102400),
                'file_types': ['txt', 'csv', 'json']
            },
            'compressor': {
                'original_size': random.randint(5000, 20000),
                'compressed_size': random.randint(1000, 5000),
                'compression_ratio': round(random.uniform(0.2, 0.7), 2)
            }
        }
        
        # æå–æ“ä½œç±»å‹
        for op_type, result in operations.items():
            if op_type in tool_name.lower():
                return result
        
        return {'status': 'completed', 'operation': 'file_operation'}
    
    def _simulate_data_processing(self, tool_name: str, state: ExecutionState) -> Dict:
        """æ¨¡æ‹Ÿæ•°æ®å¤„ç†"""
        base_records = random.randint(50, 200)
        
        operations = {
            'parser': {
                'records_parsed': base_records,
                'parse_errors': random.randint(0, 5),
                'format_detected': random.choice(['json', 'csv', 'xml']),
                'schema_valid': True
            },
            'transformer': {
                'records_input': base_records,
                'records_output': base_records,
                'transformations_applied': ['normalize', 'clean', 'format'],
                'duration_ms': random.randint(100, 1000)
            },
            'validator': {
                'records_checked': base_records,
                'valid_records': int(base_records * 0.95),
                'invalid_records': int(base_records * 0.05),
                'validation_rules': ['type_check', 'range_check', 'format_check']
            },
            'filter': {
                'records_input': base_records,
                'records_output': int(base_records * random.uniform(0.6, 0.9)),
                'filter_criteria': 'status=active AND score>0.5',
                'filters_applied': 2
            },
            'aggregator': {
                'records_processed': base_records,
                'groups_created': random.randint(5, 15),
                'aggregations': {
                    'sum': round(random.uniform(1000, 5000), 2),
                    'avg': round(random.uniform(10, 100), 2),
                    'count': base_records
                }
            }
        }
        
        # æå–æ“ä½œç±»å‹
        for op_type, result in operations.items():
            if op_type in tool_name.lower():
                return result
        
        return {'records_processed': base_records}
    
    def _simulate_network_operation(self, tool_name: str, state: ExecutionState) -> Dict:
        """æ¨¡æ‹Ÿç½‘ç»œæ“ä½œ"""
        operations = {
            'fetcher': {
                'status_code': 200,
                'data': {
                    'items': random.randint(10, 50),
                    'total': random.randint(100, 500),
                    'page': 1
                },
                'response_time_ms': random.randint(50, 500),
                'headers': {'content-type': 'application/json'}
            },
            'poster': {
                'status_code': 201,
                'created_id': f'resource_{random.randint(10000, 99999)}',
                'location': f'/api/resources/{random.randint(10000, 99999)}',
                'response_time_ms': random.randint(100, 1000)
            },
            'monitor': {
                'status': 'healthy',
                'latency_ms': random.randint(10, 100),
                'uptime_percent': round(random.uniform(99.0, 99.99), 2),
                'last_check': datetime.now().isoformat()
            },
            'router': {
                'route_selected': f'/api/v{random.randint(1, 3)}/endpoint',
                'backend_server': f'server-{random.randint(1, 5)}',
                'load_balanced': True
            },
            'validator': {
                'ssl_valid': True,
                'certificate_expiry_days': random.randint(30, 365),
                'response_valid': True,
                'schema_matches': True
            }
        }
        
        # æå–æ“ä½œç±»å‹
        for op_type, result in operations.items():
            if op_type in tool_name.lower():
                return result
        
        return {'status': 'success', 'operation': 'network'}
    
    def _simulate_computation(self, tool_name: str, state: ExecutionState) -> Dict:
        """æ¨¡æ‹Ÿè®¡ç®—æ“ä½œ"""
        operations = {
            'calculator': {
                'result': round(random.uniform(0, 1000), 4),
                'formula': 'sum(data) * factor',
                'computation_time_ms': random.randint(10, 100)
            },
            'analyzer': {
                'metrics': {
                    'mean': round(random.uniform(40, 60), 2),
                    'std_dev': round(random.uniform(5, 15), 2),
                    'min': round(random.uniform(0, 20), 2),
                    'max': round(random.uniform(80, 100), 2)
                },
                'patterns_found': random.randint(0, 5),
                'confidence': round(random.uniform(0.7, 0.99), 2)
            },
            'predictor': {
                'prediction': round(random.uniform(100, 500), 2),
                'confidence_interval': [
                    round(random.uniform(80, 100), 2),
                    round(random.uniform(500, 600), 2)
                ],
                'model_accuracy': round(random.uniform(0.8, 0.95), 2)
            },
            'simulator': {
                'iterations_run': random.randint(1000, 10000),
                'convergence_achieved': True,
                'final_state': {
                    'value': round(random.uniform(0, 1), 4),
                    'stable': True
                }
            },
            'optimizer': {
                'optimal_value': round(random.uniform(0, 100), 2),
                'parameters': {
                    'x': round(random.uniform(0, 10), 2),
                    'y': round(random.uniform(0, 10), 2)
                },
                'iterations': random.randint(10, 100),
                'converged': True
            }
        }
        
        # æå–æ“ä½œç±»å‹
        for op_type, result in operations.items():
            if op_type in tool_name.lower():
                return result
        
        return {
            'result': round(random.uniform(0, 100), 2),
            'computation_time_ms': random.randint(10, 1000)
        }
    
    def _simulate_integration(self, tool_name: str, state: ExecutionState) -> Dict:
        """æ¨¡æ‹Ÿé›†æˆæ“ä½œ"""
        operations = {
            'authenticator': {
                'auth_token': f'token_{random.randint(100000, 999999)}',
                'expires_in': 3600,
                'token_type': 'Bearer',
                'scopes': ['read', 'write']
            },
            'mapper': {
                'mappings_created': random.randint(10, 50),
                'fields_mapped': random.randint(20, 100),
                'mapping_conflicts': random.randint(0, 3),
                'auto_resolved': True
            },
            'connector': {
                'connection_id': f'conn_{random.randint(1000, 9999)}',
                'status': 'established',
                'protocol': random.choice(['HTTP', 'HTTPS', 'WebSocket']),
                'latency_ms': random.randint(10, 100)
            },
            'scheduler': {
                'job_id': f'job_{random.randint(10000, 99999)}',
                'scheduled_time': datetime.now().isoformat(),
                'frequency': random.choice(['hourly', 'daily', 'weekly']),
                'status': 'scheduled'
            },
            'queue': {
                'message_id': f'msg_{random.randint(100000, 999999)}',
                'queue_position': random.randint(1, 100),
                'estimated_processing_time': random.randint(1, 60),
                'priority': random.choice(['low', 'medium', 'high'])
            }
        }
        
        # æå–æ“ä½œç±»å‹
        for op_type, result in operations.items():
            if op_type in tool_name.lower():
                return result
        
        return {
            'status': 'connected',
            'integration_point': 'api_v2'
        }
    
    def _simulate_utility(self, tool_name: str, state: ExecutionState) -> Dict:
        """æ¨¡æ‹Ÿå·¥å…·æ“ä½œ"""
        operations = {
            'cache': {
                'operation': random.choice(['get', 'set']),
                'cache_hit': random.choice([True, False]),
                'items_cached': random.randint(10, 100),
                'memory_usage_mb': round(random.uniform(10, 100), 2),
                'ttl_seconds': 3600
            },
            'logger': {
                'logs_written': random.randint(1, 20),
                'log_level': random.choice(['DEBUG', 'INFO', 'WARNING']),
                'log_file': f'/logs/app_{datetime.now().strftime("%Y%m%d")}.log',
                'size_kb': random.randint(10, 1000)
            },
            'tracker': {
                'events_tracked': random.randint(5, 50),
                'tracking_id': f'track_{random.randint(100000, 999999)}',
                'session_duration_seconds': random.randint(60, 3600),
                'user_actions': ['click', 'view', 'submit']
            },
            'notifier': {
                'notifications_sent': random.randint(1, 10),
                'channels': random.choice([['email'], ['email', 'sms'], ['push']]),
                'delivery_status': 'delivered',
                'read_receipts': random.randint(0, 5)
            },
            'helper': {
                'operations_completed': random.randint(1, 10),
                'helper_type': random.choice(['format', 'validate', 'convert']),
                'processing_time_ms': random.randint(10, 100)
            }
        }
        
        # æå–æ“ä½œç±»å‹
        for op_type, result in operations.items():
            if op_type in tool_name.lower():
                return result
        
        return {'status': 'completed', 'utility_operation': 'generic'}
    
    def _simulate_generic(self, tool_name: str, state: ExecutionState) -> Dict:
        """é€šç”¨å·¥å…·æ¨¡æ‹Ÿ"""
        return {
            'status': 'completed',
            'tool': tool_name,
            'timestamp': datetime.now().isoformat(),
            'execution_context': {
                'step': state.current_step,
                'total_tools_executed': len(state.executed_tools)
            }
        }
    
    # === è¾…åŠ©æ–¹æ³• ===

    def _get_tool_category(self, tool_name: str) -> str:
        """è·å–å·¥å…·ç±»åˆ«"""
        # ä½¿ç”¨ç»Ÿä¸€ç®¡ç†å™¨  # <- ä¿®æ”¹äº†è¿™ä¸€è¡Œ
        if tool_name in self.tool_registry:  # <- ä¿®æ”¹äº†è¿™ä¸€è¡Œ
            capability = self.tool_registry.get(tool_name)  # <- ä¿®æ”¹äº†è¿™ä¸€è¡Œ
            return self.tool_capability_manager.get_category(capability)  # <- ä¿®æ”¹äº†è¿™ä¸€è¡Œ
        
        # Fallback: ä»å·¥å…·åæ¨æ–­
        categories = [
            'file_operations', 'data_processing', 'network',
            'computation', 'integration', 'utility'
        ]
        
        tool_lower = tool_name.lower()
        for category in categories:
            if category.replace('_', '') in tool_lower.replace('_', ''):
                return category
        
        return 'generic'
    

    def _generate_error_message(self, tool_name: str) -> str:
        """ç”Ÿæˆé”™è¯¯æ¶ˆæ¯ - ä¼˜å…ˆä½¿ç”¨å·¥å…·ç‰¹å®šçš„é”™è¯¯å®šä¹‰"""
        # ä¼˜å…ˆä»å®Œæ•´æ³¨å†Œè¡¨è·å–å·¥å…·ä¿¡æ¯
        tool_info = self.full_tool_registry.get(tool_name, {})  # <- ä¿®æ”¹ï¼šä½¿ç”¨full_tool_registry
        
        # å¦‚æœå®Œæ•´æ³¨å†Œè¡¨æ²¡æœ‰ï¼Œé™çº§åˆ°åŸå§‹æ³¨å†Œè¡¨
        if not tool_info:
            tool_info = self.tool_registry.get(tool_name, {})
        
        # è·å–å·¥å…·å®šä¹‰çš„é”™è¯¯åˆ—è¡¨
        tool_errors = self._get_tool_attribute(tool_info, 'errors', [])
        
        # å¦‚æœå·¥å…·å®šä¹‰äº†é”™è¯¯ï¼Œä½¿ç”¨å·¥å…·ç‰¹å®šçš„é”™è¯¯
        if tool_errors and len(tool_errors) > 0:
            # éšæœºé€‰æ‹©ä¸€ä¸ªé”™è¯¯
            selected_error = random.choice(tool_errors)
            
            # å¤„ç†ä¸åŒçš„é”™è¯¯æ ¼å¼
            if isinstance(selected_error, dict):
                error_code = selected_error.get('code', 'UNKNOWN_ERROR')
                error_desc = selected_error.get('description', 'An error occurred')
            elif hasattr(selected_error, 'code') and hasattr(selected_error, 'description'):
                # å¦‚æœæ˜¯ToolErrorå¯¹è±¡
                error_code = selected_error.code
                error_desc = selected_error.description
            else:
                # é»˜è®¤æ ¼å¼
                error_code = 'UNKNOWN_ERROR'
                error_desc = str(selected_error)
            
            # æ·»åŠ é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            context_additions = {
                'TIMEOUT': f' (after {random.randint(10, 60)} seconds)',
                'NETWORK_ERROR': f' (connection to {random.choice(["server", "endpoint", "service"])} failed)',
                'FILE_NOT_FOUND': f' (path: /data/{tool_name}_{random.randint(100, 999)}.dat)',
                'PERMISSION_DENIED': f' (required permission: {random.choice(["read", "write", "execute"])})',
                'INVALID_INPUT': f' (expected: {random.choice(["JSON", "XML", "CSV"])} format)',
                'DEPENDENCY_ERROR': f' (missing: {random.choice(["data source", "configuration", "previous step"])})'
            }
            
            # å¦‚æœé”™è¯¯ä»£ç æœ‰å¯¹åº”çš„ä¸Šä¸‹æ–‡ï¼Œæ·»åŠ å®ƒ
            context = context_additions.get(error_code, '')
            
            return f"{error_code}: {error_desc}{context}"
        
        # å¦‚æœå·¥å…·æ²¡æœ‰å®šä¹‰é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤é”™è¯¯æ¨¡æ¿ï¼ˆå‘åå…¼å®¹ï¼‰
        else:
            print("fhaosfhasiofhaioshdcoicas ioadncobadsdcobausodcasincdoasicaisncda\n \n")
            default_error_templates = [
                ("OPERATION_FAILED", "Operation could not be completed"),
                ("INVALID_INPUT", "Input validation failed"),
                ("TIMEOUT", "Operation timed out"),
                ("DEPENDENCY_ERROR", "Required dependencies are not available"),
                ("RESOURCE_ERROR", "Resource temporarily unavailable")
            ]
            
            error_code, error_desc = random.choice(default_error_templates)
            return f"{error_code}: {error_desc} for tool '{tool_name}'"
        

    def _extract_tool_info_requests(self, response: str) -> List[str]:
        """æå–å·¥å…·è¯¦æƒ…æŸ¥è¯¢è¯·æ±‚"""
        pattern = r'<tool_info>(.*?)</tool_info>'
        matches = re.findall(pattern, response, re.DOTALL)
        tool_names = [match.strip() for match in matches]
        
        for tool_name in tool_names:
            print(f"  [INFO] Tool info request: {tool_name}")
        
        return tool_names

    def _check_completion_signal(self, response: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å®Œæˆä¿¡å·"""
        completion_signals = [
            "TASK_COMPLETED",
            "task completed",
            "task is complete",
            "finished executing",
            "all steps completed",
            "workflow complete",
            "done with the task",
            "successfully completed the task",
            "task has been completed"
        ]
        
        response_lower = response.lower()
        return any(signal.lower() in response_lower for signal in completion_signals)
    


    def _evaluate_success(self, state: ExecutionState) -> Tuple[SuccessLevel, Dict[str, Any]]:
        """è¯„ä¼°ä»»åŠ¡æˆåŠŸçº§åˆ« - ä¸¥æ ¼çš„åˆ†çº§åˆ¤å®š"""
        success_level, _ = self._evaluate_success_detailed(state)
        return success_level in ("full_success", "partial_success")
    
    def _extract_final_outputs(self, state: ExecutionState) -> Dict[str, Any]:
        """æå–æœ€ç»ˆè¾“å‡º"""
        outputs = {}
        
        # æ”¶é›†æ‰€æœ‰æˆåŠŸå·¥å…·çš„è¾“å‡º
        for result in state.execution_history:
            # å¤„ç†dictæˆ–å¯¹è±¡
            success = result.get('success', False) if isinstance(result, dict) else result.success
            output = result.get('output') if isinstance(result, dict) else result.output
            tool_name = result.get('tool', result.get('tool_name', '')) if isinstance(result, dict) else result.tool_name
            if success and output:
                outputs[tool_name] = output
        
        # ç‰¹åˆ«æ ‡è®°è¾“å‡ºç±»å·¥å…·çš„ç»“æœ
        final_outputs = {}
        output_keywords = ['writer', 'export', 'save', 'post', 'publish', 'notifier', 'poster']
        
        for tool_name, output in outputs.items():
            if any(keyword in tool_name.lower() for keyword in output_keywords):
                final_outputs[tool_name] = output
        
        return {
            'all_outputs': outputs,
            'final_outputs': final_outputs,
            'summary': {
                'total_tools_executed': len(state.executed_tools),
                'unique_tools': len(set(state.executed_tools)),
                'successful_executions': sum(1 for r in state.execution_history if r.success),
                'failed_executions': sum(1 for r in state.execution_history if not r.success),
                'final_status': 'completed' if state.task_completed else 'incomplete',
                'required_tools_coverage': self._calculate_coverage(state)
            }
        }
    
    def _calculate_coverage(self, state: ExecutionState) -> Dict[str, Any]:
        """è®¡ç®—å¿…éœ€å·¥å…·çš„è¦†ç›–ç‡"""
        if not state.required_tools:
            return {'required_tools': 0, 'executed': 0, 'coverage': 1.0}
        
        executed_required = [t for t in state.required_tools if t in state.executed_tools]
        
        return {
            'required_tools': len(state.required_tools),
            'executed': len(executed_required),
            'coverage': len(executed_required) / len(state.required_tools),
            'missing': [t for t in state.required_tools if t not in state.executed_tools]
        }