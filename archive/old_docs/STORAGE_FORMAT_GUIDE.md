# å­˜å‚¨æ ¼å¼ä½¿ç”¨æŒ‡å—

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### 1. é€‰æ‹©å­˜å‚¨æ ¼å¼

è¿è¡Œæµ‹è¯•æ—¶ï¼Œç³»ç»Ÿä¼šé¦–å…ˆè¯¢é—®æ‚¨é€‰æ‹©å“ªç§å­˜å‚¨æ ¼å¼ï¼š

```bash
./run_systematic_test_final.sh
```

æ‚¨ä¼šçœ‹åˆ°ï¼š
```
========================================
é€‰æ‹©æ•°æ®å­˜å‚¨æ ¼å¼
========================================
è¯·é€‰æ‹©æ•°æ®å­˜å‚¨æ ¼å¼ï¼š

  1) ğŸ“„ JSONæ ¼å¼ (ä¼ ç»Ÿæ–¹å¼ï¼Œå…¼å®¹æ€§å¥½)
  2) ğŸš€ Parquetæ ¼å¼ (æ¨èï¼šé«˜æ€§èƒ½ï¼Œé˜²æ•°æ®ä¸¢å¤±)

Parquetä¼˜åŠ¿ï¼š
  â€¢ å¢é‡å†™å…¥ï¼Œæ°¸ä¸è¦†ç›–
  â€¢ ä¸­æ–­å®‰å…¨ï¼Œæ•°æ®ä¸ä¸¢å¤±
  â€¢ å¹¶å‘å†™å…¥ä¸å†²çª
  â€¢ æŸ¥è¯¢é€Ÿåº¦å¿«100å€
  â€¢ æ–‡ä»¶å¤§å°å‡å°‘80%

è¯·é€‰æ‹© [1-2] (é»˜è®¤1):
```

### 2. æˆ–é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®

```bash
# ä½¿ç”¨Parquetæ ¼å¼ï¼ˆæ¨èï¼‰
export STORAGE_FORMAT=parquet
./run_systematic_test_final.sh

# ä½¿ç”¨JSONæ ¼å¼ï¼ˆä¼ ç»Ÿï¼‰
export STORAGE_FORMAT=json
./run_systematic_test_final.sh

# ä¸´æ—¶æŒ‡å®š
STORAGE_FORMAT=parquet ./run_systematic_test_final.sh
```

## ğŸ“Š æ ¼å¼å¯¹æ¯”

| ç‰¹æ€§ | JSON | Parquet |
|------|------|---------|
| **å¹¶å‘å®‰å…¨** | âŒ ä¼šè¦†ç›– | âœ… å¢é‡å†™å…¥ |
| **ä¸­æ–­æ¢å¤** | âŒ æ•°æ®ä¸¢å¤± | âœ… è‡ªåŠ¨æ¢å¤ |
| **æ–‡ä»¶å¤§å°** | å¤§ | å°80% |
| **æŸ¥è¯¢é€Ÿåº¦** | æ…¢ | å¿«100å€ |
| **å…¼å®¹æ€§** | âœ… æ‰€æœ‰ç‰ˆæœ¬ | éœ€è¦pandas |
| **æ¨èåœºæ™¯** | å•è¿›ç¨‹æµ‹è¯• | å¹¶å‘æµ‹è¯• |

## ğŸ”„ æ•°æ®è¿ç§»

### ä»JSONè¿ç§»åˆ°Parquet

```bash
# è‡ªåŠ¨è¿ç§»æ‰€æœ‰å†å²æ•°æ®
python migrate_to_parquet.py

# æˆ–æŒ‡å®šç‰¹å®šæ–‡ä»¶
python migrate_to_parquet.py pilot_bench_cumulative_results/master_database.json
```

### ä»Parquetå¯¼å‡ºä¸ºJSON

```python
from parquet_data_manager import ParquetDataManager
manager = ParquetDataManager()
manager.export_to_json(Path("export.json"))
```

## ğŸ› ï¸ æŠ€æœ¯ç»†èŠ‚

### Parquetå­˜å‚¨ç»“æ„

```
pilot_bench_parquet_data/
â”œâ”€â”€ test_results.parquet       # ä¸»æ•°æ®æ–‡ä»¶
â”œâ”€â”€ model_stats.parquet        # æ¨¡å‹ç»Ÿè®¡
â””â”€â”€ incremental/               # å¢é‡æ•°æ®ç›®å½•
    â”œâ”€â”€ increment_12345_*.parquet  # è¿›ç¨‹12345çš„å¢é‡æ•°æ®
    â”œâ”€â”€ increment_12346_*.parquet  # è¿›ç¨‹12346çš„å¢é‡æ•°æ®
    â””â”€â”€ transaction_*.tmp          # æœªå®Œæˆçš„äº‹åŠ¡
```

### å·¥ä½œåŸç†

1. **å¢é‡å†™å…¥**ï¼šæ¯ä¸ªè¿›ç¨‹å†™å…¥ç‹¬ç«‹çš„å¢é‡æ–‡ä»¶
2. **å®šæœŸåˆå¹¶**ï¼šç³»ç»Ÿè‡ªåŠ¨å°†å¢é‡æ•°æ®åˆå¹¶åˆ°ä¸»æ–‡ä»¶
3. **äº‹åŠ¡æ¢å¤**ï¼šä¸­æ–­çš„å†™å…¥ä¿å­˜åœ¨transactionæ–‡ä»¶ä¸­ï¼Œä¸‹æ¬¡å¯åŠ¨æ—¶æ¢å¤

### JSONå­˜å‚¨ç»“æ„

```
pilot_bench_cumulative_results/
â””â”€â”€ master_database.json       # å•ä¸€JSONæ–‡ä»¶ï¼ˆæ‰€æœ‰æ•°æ®ï¼‰
```

## âš ï¸ é‡è¦æç¤º

### å¹¶å‘æµ‹è¯•åœºæ™¯

å¦‚æœæ‚¨è¿è¡Œå¤šä¸ªå¹¶å‘æµ‹è¯•è¿›ç¨‹ï¼Œ**å¼ºçƒˆå»ºè®®ä½¿ç”¨Parquetæ ¼å¼**ï¼š

```bash
# è®¾ç½®ä¸ºParquet
export STORAGE_FORMAT=parquet

# è¿è¡Œå¤šä¸ªå¹¶å‘æµ‹è¯•ï¼ˆå®‰å…¨ï¼‰
./run_systematic_test_final.sh &
./run_systematic_test_final.sh &
./run_systematic_test_final.sh &
```

ä½¿ç”¨JSONæ ¼å¼æ—¶ï¼Œå¤šä¸ªè¿›ç¨‹ä¼šç›¸äº’è¦†ç›–æ•°æ®ï¼

### å®‰è£…ä¾èµ–

Parquetæ ¼å¼éœ€è¦é¢å¤–ä¾èµ–ï¼š

```bash
pip install pandas pyarrow
```

## ğŸ” ç›‘æ§å’Œç»´æŠ¤

### æŸ¥çœ‹Parquetæ•°æ®ç»Ÿè®¡

```python
from parquet_data_manager import ParquetDataManager
manager = ParquetDataManager()

# æŸ¥è¯¢æ•°æ®
df = manager.query_model_stats()
print(f"æ€»è®°å½•æ•°: {len(df)}")
print(f"æ¨¡å‹åˆ†å¸ƒ:\n{df['model'].value_counts()}")

# è®¡ç®—ç»Ÿè®¡
stats = manager.compute_statistics(df)
print(f"æ€»æˆåŠŸç‡: {stats['success_rate']:.2%}")
```

### åˆå¹¶å¢é‡æ•°æ®

```python
# æ‰‹åŠ¨è§¦å‘åˆå¹¶ï¼ˆé€šå¸¸è‡ªåŠ¨æ‰§è¡Œï¼‰
manager.consolidate_incremental_data()
```

### æ¢å¤ä¸­æ–­çš„äº‹åŠ¡

```python
from parquet_data_manager import SafeWriteManager
safe_manager = SafeWriteManager(manager)
recovered = safe_manager.recover_transactions()
print(f"æ¢å¤äº†{recovered}æ¡è®°å½•")
```

## ğŸ“ ä»£ç é›†æˆ

### åœ¨Pythonè„šæœ¬ä¸­ä½¿ç”¨

```python
import os

# è®¾ç½®å­˜å‚¨æ ¼å¼
os.environ['STORAGE_FORMAT'] = 'parquet'  # æˆ– 'json'

# å¯¼å…¥ç»Ÿä¸€æ¥å£ï¼ˆè‡ªåŠ¨é€‰æ‹©æ­£ç¡®çš„åç«¯ï¼‰
from storage_backend_manager import (
    add_test_result,
    check_progress,
    finalize
)

# ä½¿ç”¨æ–¹æ³•å®Œå…¨ç›¸åŒ
add_test_result(
    model="gpt-4o-mini",
    task_type="simple_task",
    prompt_type="baseline",
    success=True,
    execution_time=2.5
)

# æ£€æŸ¥è¿›åº¦
progress = check_progress("gpt-4o-mini", target_count=100)
print(f"å®Œæˆç‡: {progress['completion_rate']:.1f}%")

# åŒæ­¥æ•°æ®
finalize()
```

### åœ¨Shellè„šæœ¬ä¸­ä½¿ç”¨

```bash
#!/bin/bash

# è®¾ç½®å­˜å‚¨æ ¼å¼
export STORAGE_FORMAT=parquet

# è¿è¡ŒPythonè„šæœ¬ï¼ˆä¼šè‡ªåŠ¨ä½¿ç”¨Parquetï¼‰
python batch_test_runner.py --model gpt-4o-mini

# æˆ–ç›´æ¥åœ¨å‘½ä»¤ä¸­æŒ‡å®š
STORAGE_FORMAT=json python smart_batch_runner.py --model qwen2.5-72b
```

## ğŸš€ æœ€ä½³å®è·µ

1. **ç”Ÿäº§ç¯å¢ƒ**ï¼šä½¿ç”¨Parquet
2. **å¼€å‘æµ‹è¯•**ï¼šJSONä¾¿äºè°ƒè¯•
3. **æ•°æ®åˆ†æ**ï¼šParquetæ€§èƒ½æ›´å¥½
4. **é•¿æœŸå­˜å‚¨**ï¼šParquetå‹ç¼©ç‡é«˜

## ğŸ“ æ•…éšœæ’é™¤

### é—®é¢˜ï¼šParquetä¾èµ–æœªå®‰è£…
```bash
pip install pandas pyarrow
```

### é—®é¢˜ï¼šæ•°æ®è¿ç§»å¤±è´¥
```bash
# æ£€æŸ¥æƒé™
ls -la pilot_bench_cumulative_results/
ls -la pilot_bench_parquet_data/

# æ‰‹åŠ¨åˆ›å»ºç›®å½•
mkdir -p pilot_bench_parquet_data/incremental
```

### é—®é¢˜ï¼šå¹¶å‘å†™å…¥å†²çªï¼ˆJSONï¼‰
ç«‹å³åˆ‡æ¢åˆ°Parquetï¼š
```bash
export STORAGE_FORMAT=parquet
```

---

**ç‰ˆæœ¬**: 1.0.0  
**æ›´æ–°æ—¶é—´**: 2025-08-16  
**ä½œè€…**: Claude Assistant